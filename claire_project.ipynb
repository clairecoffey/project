{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "claire_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clairecoffey/project/blob/master/claire_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep76GcW0r5EF",
        "colab_type": "text"
      },
      "source": [
        "# Fairness and the bias-variance trade-off \n",
        "\n",
        "## Claire Coffey\n",
        "\n",
        "## June 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt8eZN7L71OB",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we are studying bias and variance errors in the context of fairness, by exploring recidivism data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5j4K9fEtccc",
        "colab_type": "text"
      },
      "source": [
        "## Imports and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwPz0FbDrdOB",
        "colab_type": "text"
      },
      "source": [
        "Imports: first import the relevant libraries used throughout. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cpVvJ1Dwm48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncHkSsNUw48L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# svm.SVC?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3xUTfnrkM0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojFZOY-LtsdL",
        "colab_type": "text"
      },
      "source": [
        "# Read in recidivism data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLIFxjZ9roCK",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we are studying recidivism data. We utilise the COMPAS recidivism dataset, which uses recidivism data from Broward County jail and has been explored in the following studies:\n",
        "\n",
        "\"The accuracy, fairness, and limits of predicting recidivism\", paper available at:\n",
        "https://advances.sciencemag.org/content/4/1/eaao5580#corresp-1\n",
        "\n",
        "\"Machine Bias\" ProPublica article, available at:\n",
        "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n",
        "\n",
        "The dataset used can be found at:\n",
        "https://github.com/propublica/compas-analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmO2E_MbHUGY",
        "colab_type": "text"
      },
      "source": [
        "Here we import and read in the recidivism data. Currently, we are using a selection of 1000 samples from this dataset for our predictions (the first 1000 samples of the dataset)\n",
        "\n",
        "We use a selection \n",
        "of fields from this dataset to predict recidivism classification (1 = will reoffend; 0 = will not reoffend). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk62wPdCURBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdCKnj1kqViI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_file():\n",
        "  full_data = False\n",
        "  print(\"loading data\")\n",
        "  if full_data:\n",
        "    # full dataset\n",
        "    file_path = \"https://raw.githubusercontent.com/clairecoffey/project/master/mphilproject/compas-scores-two-years%20-%20compas-scores-two-years.csv?token=ABPC6VNTFTGQBANNUJY2O4C6XGJGY\"\n",
        "  else:\n",
        "    # small subset of first 500/1000/2000 people\n",
        "    # file_path = \"https://raw.githubusercontent.com/clairecoffey/project/master/mphilproject/500-compas-scores-two-years%20-%20Sheet1%20(1).csv?token=ABPC6VOW7CBEIIGZVE6ZJYS6YKNHO\"\n",
        "    # file_path = \"https://raw.githubusercontent.com/clairecoffey/project/master/mphilproject/1000-compas-scores-two-years%20-%20Sheet1.csv\"\n",
        "    file_path = \"https://raw.githubusercontent.com/clairecoffey/project/master/mphilproject/2000-compas-scores-2-years.csv\"\n",
        "\n",
        "  # load CSV contents\n",
        "  all_data = pd.read_csv(file_path, delimiter=',', dtype={'sex': 'category', \n",
        "                                                          'age_cat': 'category',\n",
        "                                                          'race': 'category',\n",
        "                                                          'c_charge_degree': 'category',\n",
        "                                                          'c_charge_desc': 'category',\n",
        "                                                          'r_charge_degree': 'category',\n",
        "                                                          'r_charge_desc': 'category',\n",
        "                                                          'vr_charge_degree': 'category',\n",
        "                                                          'vr_charge_desc': 'category'\n",
        "                                                          })\n",
        "  print('loaded data')\n",
        "  #shuffle into random order so we aren't always testing/training with the same people\n",
        "  #but reset index (each individual still has the same ID)\n",
        "  all_data = all_data.sample(frac=1).reset_index(drop=True)\n",
        "  return all_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1WpLQEMZUNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all_data = load_file()\n",
        "# all_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19AV7fOG0z4h",
        "colab_type": "text"
      },
      "source": [
        "## Import and process data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB8DQVf7g1Nn",
        "colab_type": "text"
      },
      "source": [
        "We import the data into a pandas DataFrame. We begin by cleaning the data, so the crime descriptions are simplified, removing duplicate categories. For example, we merge descriptions such as 'possession of cocaine' and 'possess cocaine', or 'burglary/weapon' and 'burglary and weapon', by removing prepositions, and replacing abreviations and similies. \n",
        "\n",
        "Then,  the categorical data is  split into different fields for each category, and encoded as 0 or 1. For example, an individual with characteristic \"sex: male\" would be encoded as \"male: 1, female: 0\". The sex category is then removed.\n",
        "\n",
        "We then consider which fields to use for prediction. This includes the removal of any fields/columns which contain many NaN values, since these cannot be handled by the classifiers. We choose to remove the columns with many NaNs rather than using an alternative approach such as replacing them with the average so as not to introduce other types of bias. We also then remove rows/individuals containing any further NaN values so there is no longer any NaN values present in the data. \n",
        "\n",
        "We then normalise all of the data in the dataframe, so that when fed into the classifier, the predicitons are not skewed (and potentially different forms of bias introduced).  We do this by using the StandardScaler in the sklearn preprocessing library, and we normalise the data to have a variance of 1.\n",
        "\n",
        "Finally, we define the number of testing/training samples desired and split the data into these two sets appropriately.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzJytmnMtkPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def clean_descriptions(description):\n",
        "  description = description.replace(' and ', ' ')\n",
        "  description = description.replace(' / ', ' ')\n",
        "  description = description.replace('possession', 'posess')\n",
        "  description = description.replace('possessing', 'posess')\n",
        "  description = description.replace('with', 'w/')\n",
        "  description = description.replace('w/ ', 'w/')\n",
        "  description = description.replace('w/', ' ')\n",
        "  description = description.replace('attempted', 'att')\n",
        "  description = description.replace('attempt', 'att')\n",
        "  description = description.replace('aggravated', 'agg')\n",
        "  description = description.replace('aggrav', 'agg') \n",
        "  description = description.replace(' of ', ' ')\n",
        "  return description\n",
        "\n",
        "def import_data(all_data):\n",
        "  num_testing_samples = 1600\n",
        "\n",
        "  encoded_sex = (pd.get_dummies(all_data['sex']))\n",
        "  all_data = all_data.drop(columns=['sex'])\n",
        "  all_data = all_data.join(encoded_sex)\n",
        "\n",
        "  encoded_age_cat = (pd.get_dummies(all_data['age_cat']))\n",
        "  all_data = all_data.drop(columns=['age_cat'])\n",
        "  all_data = all_data.join(encoded_age_cat)\n",
        "\n",
        "  encoded_race = (pd.get_dummies(all_data['race']))\n",
        "  all_data = all_data.drop(columns=['race'])\n",
        "  all_data = all_data.join(encoded_race)\n",
        "\n",
        "  encoded_c_charge_degree = (pd.get_dummies(all_data['c_charge_degree']))\n",
        "  all_data = all_data.drop(columns=['c_charge_degree'])\n",
        "  all_data = all_data.join(encoded_c_charge_degree, rsuffix='_c')\n",
        "\n",
        "  #these are joined with suffixes because otherwise columns overlap \n",
        "  all_data['c_charge_desc'] = all_data['c_charge_desc'].astype(str).str.lower()\n",
        "  all_data['c_charge_desc'] = all_data['c_charge_desc'].apply(clean_descriptions)\n",
        "  encoded_c_charge_desc = (pd.get_dummies(all_data['c_charge_desc']))\n",
        "  all_data = all_data.drop(columns=['c_charge_desc'])\n",
        "  all_data = all_data.join(encoded_c_charge_desc, rsuffix='_c')\n",
        "\n",
        "  encoded_r_charge_degree = (pd.get_dummies(all_data['r_charge_degree']))\n",
        "  all_data = all_data.drop(columns=['r_charge_degree'])\n",
        "  all_data = all_data.join(encoded_r_charge_degree, rsuffix='_r')\n",
        "\n",
        "  all_data['r_charge_desc'] = all_data['r_charge_desc'].astype(str).str.lower()\n",
        "  all_data['r_charge_desc'] = all_data['r_charge_desc'].apply(clean_descriptions)\n",
        "  encoded_r_charge_desc = (pd.get_dummies(all_data['r_charge_desc']))\n",
        "  all_data = all_data.drop(columns=['r_charge_desc'])\n",
        "  all_data = all_data.join(encoded_r_charge_desc, rsuffix='_r')\n",
        "\n",
        "  encoded_vr_charge_degree = (pd.get_dummies(all_data['vr_charge_degree']))\n",
        "  all_data = all_data.drop(columns=['vr_charge_degree'])\n",
        "  all_data = all_data.join(encoded_vr_charge_degree, rsuffix='_vr')\n",
        "\n",
        "  all_data['vr_charge_desc'] = all_data['vr_charge_desc'].astype(str).str.lower()\n",
        "  all_data['vr_charge_desc'] = all_data['vr_charge_desc'].apply(clean_descriptions)\n",
        "  encoded_vr_charge_desc = (pd.get_dummies(all_data['vr_charge_desc']))\n",
        "  all_data = all_data.drop(columns=['vr_charge_desc'])\n",
        "  all_data = all_data.join(encoded_vr_charge_desc, rsuffix='_vr')\n",
        "\n",
        "  all_data = all_data.drop(columns=['nan'])\n",
        "  all_data = all_data.drop(columns=['nan_vr'])\n",
        "  all_data = all_data.drop(columns=['nan_r'])\n",
        "\n",
        "  #swap the 1s and 0s in 'two_year_recid', if we want \"1\" to refer to the positive case, i.e. did not reoffend\n",
        "  # two_year_recid_swapped = pd.DataFrame(np.logical_xor(all_data['two_year_recid'].values,1).astype(int), columns=['two_year_recid_swapped'])\n",
        "  # all_data = all_data.drop(columns=['two_year_recid'])\n",
        "  # all_data = all_data.join(two_year_recid_swapped)\n",
        "\n",
        "  #drop columns not used for predictions, including info such as names, and coluns with many NaN values \n",
        "  # all_data_simplified = all_data.drop(columns=['two_year_recid', 'r_days_from_arrest', 'id','name','first','last','dob','days_b_screening_arrest','c_jail_in','c_jail_out','c_case_number','c_offense_date','c_arrest_date','r_case_number','r_offense_date','r_jail_in','r_jail_out','vr_case_number','vr_offense_date','in_custody','out_custody','start','end','violent_recid', 'age','arrest case no charge'])\n",
        "  all_data.columns = map(str.lower, all_data.columns)\n",
        "  # print(all_data_simplified.columns)\n",
        "  #dont use individual crimes, too slow, only use severity of crimes and other info\n",
        "  all_data_simplified = all_data[['juv_fel_count','juv_misd_count','juv_other_count','priors_count','is_recid','is_violent_recid','event','female','male','25 - 45','greater than 45','less than 25','african-american','asian','caucasian','hispanic','native american','other','f','m','(f1)','(f2)','(f3)','(f6)','(m1)','(m2)','(mo3)']]\n",
        "  # all_data_simplified = all_data[['juv_fel_count','juv_misd_count','juv_other_count','priors_count','is_recid','is_violent_recid','event','female','male','25 - 45','greater than 45','less than 25','african-american','caucasian','hispanic','other','f','m','(f1)','(f2)','(f3)','(m1)','(m2)','(mo3)']]\n",
        "\n",
        "  #remove rows containing NaN values \n",
        "  all_data_simplified = all_data_simplified.dropna()\n",
        "\n",
        "  #Renormalise the data so we have unit variance and mean 0 using built-in preprocessing method in sklearn\n",
        "  scaler = preprocessing.StandardScaler()\n",
        "  all_data_scaled = pd.DataFrame(scaler.fit_transform(all_data_simplified),columns=all_data_simplified.columns)\n",
        "\n",
        "  # print(\"testing normalisation, printing mean and variance: \")\n",
        "  # print(all_data_scaled.mean())\n",
        "  # print(all_data_scaled.var())\n",
        "\n",
        "  all_data_and_labels = all_data_scaled.join(all_data[['two_year_recid']])\n",
        "  # all_data_and_labels.columns = map(str.lower, all_data_and_labels.columns)\n",
        "\n",
        "  #split into training and testing with specific number of testing samples\n",
        "  #for now just set testing set to be first num_testing_samples samples in table \n",
        "  testing_data_and_labels = all_data_and_labels[:num_testing_samples]\n",
        "\n",
        "  # if(demographic_to_test != 'all'):\n",
        "    # testing_data_and_labels =  pd.DataFrame.reset_index(testing_data_and_labels.loc[testing_data_and_labels[demographic_to_test] > 0],drop=True)\n",
        "\n",
        "  #and training set to be the remainder\n",
        "  #this is also then consistent which is good for seeing patterns etc \n",
        "  training_data_and_labels = all_data_and_labels[num_testing_samples:]\n",
        "\n",
        "  # print(\"normalised\")\n",
        "  # print(training_data_and_labels)\n",
        "\n",
        "  # print(testing_data_and_labels)\n",
        "  return training_data_and_labels, testing_data_and_labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUKy0e7IBQYI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Vx5Lghqe2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training_data_and_labels, testing_data_and_labels = import_data(all_data)\n",
        "# training_data_and_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P5FvDlXt4se",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmKSjOeK4aRj",
        "colab_type": "text"
      },
      "source": [
        "##Selecting Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs36jQoqYmpp",
        "colab_type": "text"
      },
      "source": [
        "Here we select the classification model to use. We are using a selection of built-in classifiers in scikit-learn. \n",
        "\n",
        "Currently, we are using RBF SVM models (https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html). \n",
        "\n",
        "We define the boolean values ```vary_gamma ``` and  ```vary_c``` to define whether we are varying the gamma or C value in the classifiers. \n",
        "\n",
        "The model parameters are chosen in order to optimise for the overall loss, then optimised for the fairness criteria \"equalised odds\" for each demographic. This results in different models optimised for each demographic. We also have an overall \"most fair\" model, which trades off the discrimination measure for each demographic to find the 'optimal' parameters. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZv_kuCWYo_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection, neighbors, svm, gaussian_process, tree, ensemble, neural_network, metrics\n",
        "\n",
        "def define_classifiers():\n",
        "\n",
        "  vary_gamma = False\n",
        "  vary_c = False \n",
        "  polynomial = True\n",
        "  gammas = []\n",
        "  cs = []\n",
        "  classifiers = []\n",
        "  degrees = []\n",
        "\n",
        "  if vary_gamma:\n",
        "    gammas = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,5,10,50,100,500,1000]\n",
        "    # gammas = [100, 1000, 10000, 100000]\n",
        "    cs=[10000]\n",
        "    # cs = [0.1, 1, 10, 100, 1000, 10000, 100000]\n",
        "    # gammas = [0.001]\n",
        "    # gammas = [1]\n",
        "    # c_val = 1000\n",
        "    #fix size of C if varying gamma\n",
        "\n",
        "    for gamma_val in gammas:\n",
        "      for c_val in cs:\n",
        "        classifiers.append(svm.SVC(gamma=gamma_val,C=c_val, probability=True))\n",
        "\n",
        "  if vary_c:\n",
        "    cs = [10, 100, 1000, 10000, 100000, 1000000, 10000000, 10000000]\n",
        "    gamma_val = 1\n",
        "    #fix size of gamma if varying C\n",
        "    for c_val in cs:\n",
        "      classifiers.append(svm.SVC(gamma=gamma_val,C=c_val, probability=True))\n",
        "\n",
        "  if polynomial:\n",
        "    degrees = [2,3,4,5,6,7,8]\n",
        "    # degrees = [2]\n",
        "    for degree in degrees:\n",
        "      classifiers.append(svm.SVC(kernel='poly', degree=degree, probability=True))\n",
        "\n",
        "  return classifiers, gammas, cs, degrees\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQD8oVE-a4-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define_classifiers()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7PUBJeb4SQh",
        "colab_type": "text"
      },
      "source": [
        "## Bootstrapping "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxB1XKpC4fYi",
        "colab_type": "text"
      },
      "source": [
        "The classification process then uses a bootstrapping procedure with the chosen model, to generate predictions of recidivism classifications (1 = will not reoffend (positive case); 0 = will reoffend (negative case)).\n",
        "\n",
        "Bootstrapping (https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_41) is a sampling with replacement procedure. The sample size is the same as the size of the (training) dataset. The bootstrapping procedure is run many times to generate different training datasets, which will then be used for classification. In turn, the classification results will be used to calculate and study the bias and variance errors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzZ6oTWgv3FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_bootstrap(training_data_and_labels):\n",
        "  # this is one bootstrap sample \n",
        "  indices = np.random.randint(0,training_data_and_labels.shape[0] , training_data_and_labels.shape[0])\n",
        "  indices.sort()\n",
        "  data_points = []\n",
        "\n",
        "  for i in indices:\n",
        "    data_points.append(training_data_and_labels.iloc[i])\n",
        "\n",
        "  b_sample = pd.DataFrame(data_points)\n",
        "  \n",
        "  return b_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RPB3I-bwLF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b_sample = do_bootstrap(training_data_and_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yArDHhIdCfIS",
        "colab_type": "text"
      },
      "source": [
        "### Calculate average prediction for each individual over all bootstrap samples "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjQeJu-rCpkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_avg_prediction(predictions):\n",
        "  #each row is bootstrap sample, each column an individual\n",
        "  return majority_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0p40u-y5sf2",
        "colab_type": "text"
      },
      "source": [
        "## Perform classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDUs2m5A6yP3",
        "colab_type": "text"
      },
      "source": [
        "Fit the model on the training data (which is one bootstrap data sample as defined above)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaofDUc-P8Mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(clf, b_sample, testing_data_and_labels):\n",
        "\n",
        "    #training data is everything apart from two year recid 0/1 label from the bootstrap sample\n",
        "    X_train = b_sample.drop(columns=['two_year_recid'])\n",
        "    y_train = b_sample['two_year_recid']\n",
        "    X_test = testing_data_and_labels.drop(columns=['two_year_recid'])\n",
        "    y_test = testing_data_and_labels['two_year_recid']\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    soft_score = clf.decision_function(X_test)\n",
        "    y_true = y_test\n",
        "\n",
        "    return y_pred, y_true, soft_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d8e8STm77eG",
        "colab_type": "text"
      },
      "source": [
        "Perform classification for each bootstrap sample separately, and store these in a DataFrame, to be passed into the bias/variance calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm8R-Gt-OmNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(training_data_and_labels, testing_data_and_labels, clf):\n",
        "    count = 0\n",
        "\n",
        "    num_bootstraps = len(training_data_and_labels);\n",
        "    while count <= num_bootstraps:\n",
        "      b_sample = do_bootstrap(training_data_and_labels)\n",
        "      y_pred, y_true, soft_score = fit_model(clf, b_sample, testing_data_and_labels)\n",
        "      if(count == 0):\n",
        "        predictions = pd.DataFrame(pd.Series(y_pred)).transpose()\n",
        "        #true labels are the same for every sample so we only need 1 row in df\n",
        "        true_labels = pd.DataFrame(pd.Series(y_true)).transpose()\n",
        "      else:\n",
        "        predictions = predictions.append(pd.DataFrame(pd.Series(y_pred)).transpose())\n",
        "      count += 1\n",
        "      \n",
        "    return predictions, true_labels, soft_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H75T2WV0OqIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classify(training_data_and_labels, testing_data_and_labels, clf)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cs1tUOjKjPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify_noise(training_data_and_labels, testing_data_and_labels, clf):\n",
        "    count = 0\n",
        "\n",
        "    num_bootstraps = len(training_data_and_labels);\n",
        "    while count <= num_bootstraps:\n",
        "      b_sample = do_bootstrap(training_data_and_labels)\n",
        "      y_pred, y_true = fit_model(clf, b_sample, testing_data_and_labels)\n",
        "      #to calculate noise we want the predicted labels and the true labels the same\n",
        "      y_pred = y_true\n",
        "      if(count == 0):\n",
        "        predictions = pd.DataFrame(pd.Series(y_pred)).transpose()\n",
        "        #true labels are the same for every sample so we only need 1 row in df\n",
        "        true_labels = pd.DataFrame(pd.Series(y_true)).transpose()\n",
        "      else:\n",
        "        predictions = predictions.append(pd.DataFrame(pd.Series(y_pred)).transpose())\n",
        "      count += 1\n",
        "      \n",
        "    return predictions, true_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TMfhfngzvTX",
        "colab_type": "text"
      },
      "source": [
        "## Correcting for Fairness\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBQkNPgD4D6o",
        "colab_type": "text"
      },
      "source": [
        "#Fairness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frcBqdbB3M22",
        "colab_type": "text"
      },
      "source": [
        "The definition of fairness is disputed, and there is not a single correct approach to ensuring fairness in machine learning. In general, as stated in https://arxiv.org/pdf/1711.08513.pdf, fairness in machine learning can be approached in two ways: fairness of the dataset itself; fairness of the model.\n",
        "\n",
        "Since we cannot control the process by which the data is collected, and the recidivism dataset already exists (likely with human and societal biases built-in), we will not be focusing on the former category. Although, there have been recent trends within the fairness and machine learning communities to argue the importance of the fairness in data collection, for example, in http://papers.nips.cc/paper/7613-why-is-my-classifier-discriminatory.pdf, the authors discuss the necessity of correcting for bias in the dataset, an approach which may actually increase the accuracy of the predictions, in contrast to approaches that exclusively focus on correcting for fairness in the models, at the expense of accuracy. Another area in which recent trends in fairness research have addressed is the importance of developing context-aware fairness measurements (https://arxiv.org/pdf/1805.05859.pdf). However, in our project we will focus on model-based fairness correction - ensuring the machine learning models are not perpetuating existing biases, or introducing new biases. We do this by using a widely used and accepted fairness measurement which is context-independent, known as **Equalised Odds** (http://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning.pdf). This approach is not without criticism, however it provides a clear and well-motivated approach to achieving fair predictions across subgroups with different protected characteristics. We attempt to correct for fairness in relation to the protected characteristics found in the recidivism dataset (sex, race, age). Once our models are 'fair' in relation to this description, we can explore the relationship between bias and variance errors and the potential discovery of discrimination against new categories. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vab-_uQEx46Q",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Equalised Odds\n",
        "\n",
        "As stated above, we are considering fairness in relation to the equalised odds metric (http://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning.pdf). The definition as stated in this paper is as follows: \\\\\n",
        "We say that a predictor $\\hat{Y}$ satisfies equalized odds with respect to\n",
        "protected attribute $A$ and outcome $Y$, if $\\hat{Y}$ and $A$ are independent conditional on $Y$. Therefore, if the classification labels are $Y$ and $\\hat{Y}$, for an outcome $ y=1 $, $\\hat{Y}$ has equal true positive rates across all demographic groups, for example, the categories not female and female will have equal true positive rates. For an outcome  $ y=0 $, $\\hat{Y}$ has equal false positive rates across all demographic groups. This enforces equal bias and accuracy in all demographics. This can formally be stated as:\n",
        "$$ Pr \\left\\{ \\hat{Y}=1 | A = 0, Y = y \\right\\} = Pr \\left\\{ \\hat{Y}=1 | A = 0, Y = y \\right\\} , y \\in \\left\\{ 0,1 \\right\\}$$\n",
        "\n",
        "This approach punishes models that only perform well on the majority demographics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cat-Jl0kJu2C",
        "colab_type": "text"
      },
      "source": [
        "[link text](https:// [link text](https://))The following code is the implementation of equalised odds from the paper http://papers.nips.cc/paper/7151-on-fairness-and-calibration.pdf, the code is from the github repository https://github.com/gpleiss/equalized_odds_and_calibration/blob/master/eq_odds.py.\n",
        "\n",
        "This implementation equalises false positives and false negatives across demoographics, since in general, African Americans receive\n",
        "a disproportionate number of F.P. predictions as compared with Caucasians when automated risk tools are used in practice. In the context of recidivism, the 'positive case' is in fact a prediction of 0: the individual is predicted not to reoffend, so equalising false positives in this case fits with the equalised odds definition above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDXXgyFKJZOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_scores(predictions, soft_scores):\n",
        "\n",
        "  maximum = soft_scores.max()\n",
        "  minimum = soft_scores.min()\n",
        "\n",
        "  normalise = lambda x: ((x-minimum)/(maximum-minimum))\n",
        "  n_soft_scores = []\n",
        "  for score in soft_scores:\n",
        "    soft_score = normalise(score)\n",
        "    n_soft_scores.append(soft_score)\n",
        "\n",
        "  return n_soft_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPOMSx6442c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2WbfvPkLImE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def constrain_with_equalised_odds(true_labels, group_ids, demographic, soft_scores):\n",
        "\n",
        "  #create csv file containing relevant fields: prediction, label, group \n",
        "  predictions = pd.DataFrame(soft_scores, columns=['prediction'])\n",
        "  true_labels = pd.melt(true_labels).rename(columns={'value':'label'})\n",
        "  group_ids = pd.melt(group_ids).rename(columns={'value':'group'})\n",
        "  eq_odds_input = pd.concat([predictions, true_labels], axis=1)\n",
        "  eq_odds_input = pd.concat([eq_odds_input, group_ids], axis=1)\n",
        "  eq_odds_input = eq_odds_input.drop(columns=[\"variable\"])\n",
        "  # print(eq_odds_input)\n",
        "  eq_odds_input.to_csv('/content/drive/My Drive/project_data/eq_odds.csv', index=True)\n",
        "\n",
        "  !python2 \"/content/drive/My Drive/project_data/eq_odds.py\" \"/content/drive/My Drive/project_data/eq_odds.csv\"\n",
        "\n",
        "  eq_odds_pred_group_0 = pd.read_csv(filepath_or_buffer='/content/group_0.csv', delimiter=',', header=0)\n",
        "  eq_odds_pred_group_1 = pd.read_csv(filepath_or_buffer='/content/group_1.csv', delimiter=',',header=0 )\n",
        "  eq_odds_pred = pd.concat([eq_odds_pred_group_0,eq_odds_pred_group_1])\n",
        "  eq_odds_pred =  pd.DataFrame.reset_index(eq_odds_pred,drop=True)\n",
        "  eq_odds_pred['round_predictions'] = [0 if (row < 0.5) else 1 for row in eq_odds_pred['predictions']]\n",
        "\n",
        "  return eq_odds_pred['round_predictions'], eq_odds_pred['true_labels']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wo26rgsVMPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5hobrODGwef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#this method doesn't actually make anything fair, it just calculates what we need in order to configure the models to be fair \n",
        "def calc_fairness_metrics(y_true, y_pred):\n",
        "  # get confusion matrix and compute tn,fp,fn,tp\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true.iloc[0].to_numpy(), y_pred.iloc[0].to_numpy()).ravel()\n",
        "  print(\"true negatives:\", tn, \"rate:\" , tn/(tn+fp+fn+tp), \"false positives:\", fp, \"rate:\", fp/(tn+fp+fn+tp) ,\"false negatives:\", fn,\"rate:\", fn/(tn+fp+fn+tp), \"true positives:\",tp,\"rate:\", tp/(tn+fp+fn+tp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnKB0sC3uU6-",
        "colab_type": "text"
      },
      "source": [
        "# Compute bias/variance errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdwnNxEnWqth",
        "colab_type": "text"
      },
      "source": [
        "Using all these bootstrap predictions, we calculate the average misclassification error which is the same as the zero-one loss. This is done by first calculating the overall misclassification loss across bootstrap sample predictions, finding the average misclassification error for each datapoint (individual). As described in:\n",
        "http://www.cems.uwe.ac.uk/~irjohnso/coursenotes/uqc832/tr-bias.pdf\n",
        "\n",
        "We can then decompose the error into the errors due to bias, and the errors due to variance, in order to study the behaviour of the model and the bias/variance tradeoff. This decomposition for classification is described in: \n",
        "https://homes.cs.washington.edu/~pedrod/bvd.pdf\n",
        "https://pdfs.semanticscholar.org/9253/f3e13bca7e845e60394d85ddaec0d4cfc6d6.pdf  \n",
        "\n",
        "<!-- https://www.stat.berkeley.edu/users/breiman/arcall96.pdf.  -->\n",
        "\n",
        "<!-- The error is also comprised of an error due to noise (in addition to bias and variance). However, as stated in http://papers.nips.cc/paper/7613-why-is-my-classifier-discriminatory.pdf, the noise is dependent on the data, not the model, so comparing the discrimination level in the form of bias and variance errors, the noise terms cancel since they are independent of the model. Therefore, differences in bias can be explored even without knowing the underlying noise of the data.  -->\n",
        "\n",
        "We calculate the bias and variance errors for each individual, following zero-one loss rules under misclassification loss, as described by Domingos https://homes.cs.washington.edu/~pedrod/bvd.pdf, http://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/. We can then calculate the overall average bias error and variance error for the prediction. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-7WHEx8dq6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_bias_variance(predictions, true_labels):\n",
        "\n",
        "  # print(\"predictions: \")\n",
        "  # print(predictions)\n",
        "  # print(\"true labels: \")\n",
        "\n",
        "  biases = []\n",
        "  variances = []\n",
        "  avg_errors = []\n",
        "  misclassified_individuals = []\n",
        "  losses = []\n",
        "  noises = []\n",
        "\n",
        "  # calculate the bias and variance for each value of X,y\n",
        "  # for misclassification loss\n",
        "\n",
        "  #to get the main prediction for each datapoint \n",
        "  main_predictions_first = predictions.mode(numeric_only=True)\n",
        "  main_predictions = pd.melt(main_predictions_first).iloc[:,1]\n",
        "\n",
        "  #find whether each element is misclassified for each bootstrap sample \n",
        "  main_predictions_misclassified_relative_to_true = main_predictions_first.apply(lambda z : z != true_labels.iloc[0], axis=1)\n",
        "  #find if each prediction is the same as the true prediction \n",
        "  predictions_misclassified_relative_to_true = predictions.apply(lambda x : x != true_labels.iloc[0], axis=1)\n",
        "  #find if the main (mode) prediction is the same as the actual prediction\n",
        "  predictions_misclassified_relative_to_main = predictions.apply(lambda y : y != main_predictions, axis = 1)\n",
        "\n",
        "  # predictions_misclassified_noise = noise_predictions.apply(lambda z : z != true_labels.iloc[0], axis=1)\n",
        "\n",
        "  main_misclassified_true_counts = main_predictions_misclassified_relative_to_true.apply(np.sum)\n",
        "  #count number of times misclassified for each datapoint across all bootstrap samples \n",
        "  misclassified_true_counts = predictions_misclassified_relative_to_true.apply(np.sum)\n",
        "  misclassified_main_counts = predictions_misclassified_relative_to_main.apply(np.sum)\n",
        "  # misclassified_noise_counts = predictions_misclassific_noise.apply(np.sum)\n",
        "\n",
        "\n",
        "  #average misclassification error for each individual/datapoint \n",
        "  #same as probability of incorrect classification\n",
        "  avg_true_errors = misclassified_true_counts.apply(lambda a : np.divide(a,len(predictions)))\n",
        "  avg_main_errors = misclassified_main_counts.apply(lambda b : np.divide(b,len(predictions)))\n",
        "  avg_main_true_errors = main_misclassified_true_counts.apply(lambda c : np.divide(c,len(main_predictions_first)))\n",
        "  # avg_noise_errors = misclassified_noise_counts.apply(lambda c : np.divide(c, len(predictions)))\n",
        "\n",
        "  for i in range(len(avg_true_errors)):\n",
        "    # if average error is less than 0.5 then it means the main prediction is the same as the optimal one\n",
        "    avg_main_true_error = avg_main_true_errors[i]\n",
        "    avg_true_error = avg_true_errors[i]\n",
        "    avg_main_error = avg_main_errors[i]\n",
        "    bias = 0 if avg_main_true_error <=0.5 else 1\n",
        "    variance = avg_main_error\n",
        "    #noise is the underlying variance of the data: error when the optimal and true classifications are the same\n",
        "    #independent of model, we can say it is 0 as doesn't effect bias/var relationship\n",
        "    #and when we tested this, it returned a value of 0 (all labels predicted correctly across all samples so no loss incurred)\n",
        "    noise = 0\n",
        "    # print('noise: ',noise)\n",
        "    c1 = ((2*(1-avg_true_error))-1)\n",
        "    c2 = 1 if avg_main_true_error <= 0.5 else -1\n",
        "    #loss according to domingos' decomposition\n",
        "    loss = (c1*noise) + bias + (c2*variance)\n",
        "    biases.append(bias)\n",
        "    variances.append(variance)\n",
        "    noises.append(noise)\n",
        "    losses.append(loss)\n",
        "    if avg_true_error > 0.5:\n",
        "      misclassified_individuals.append(i)\n",
        "\n",
        "  avg_bias = np.mean(biases)\n",
        "  # avg_var = abs(np.mean(avg_errors) - avg_bias)\n",
        "  avg_var = np.mean(variances)\n",
        "  # avg_error = np.mean(avg_errors)\n",
        "  avg_loss = np.mean(losses)\n",
        "  avg_noise = np.mean(noises)\n",
        "\n",
        "  print(\"average loss:\") \n",
        "  print(avg_loss)\n",
        "  print(\"average noise:\")\n",
        "  print(avg_noise)\n",
        "  print(\"average bias:\")\n",
        "  print(avg_bias)\n",
        "  print(\"average variance:\")\n",
        "  print(avg_var)\n",
        "\n",
        "  return avg_bias, avg_var, avg_loss, misclassified_individuals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1ygDcLeBeNq",
        "colab_type": "text"
      },
      "source": [
        "## Identifying Categories of Discrimination "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAxWqE2JBiT9",
        "colab_type": "text"
      },
      "source": [
        "We hope to address the question: Are models that exhibit high bias errors likely to introduce new categories of discrimination? \n",
        "\n",
        "We can therefore look at the bias and variance errors for different models.\n",
        "\n",
        "\n",
        "We want to see that if the variance is low and bias high, is it consistently discriminating against a certain subgroup, potentially introducing a new type of discrimination? Unlike other work such as http://papers.nips.cc/paper/7613-why-is-my-classifier-discriminatory.pdf, it doesn't have to be a protected characteristic.\n",
        "\n",
        "\n",
        "\n",
        "I think perhaps after fairness correction, we can look at who is misclassified and then what they have in common? Or, we can extract each \"subgroup\" based on whatever characteristics and analyse these - i.e. did FPR/FNR go up/down for a different subgroup after fairness correction?  Do this in same way as we do for \"demographics\" initially used for fairness correction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS-RcQVHudhq",
        "colab_type": "text"
      },
      "source": [
        "# Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kav2TxMqeTy2",
        "colab_type": "text"
      },
      "source": [
        "Creating the appropriate plots to visualise our results. We plot: \n",
        "\n",
        "1.   Bias error vs Variance error\n",
        "2.   Gamma value of RBF SVM vs Variance error\n",
        "3.   Gamma value of RBF SVM vs Bias error\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TcztpNvvfDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt                                  \n",
        "def plot_bias_variance(biases, variances, gammas, cs, degrees, losses):   \n",
        "  # print(\"plotting bias/var\") \n",
        "  # plt.scatter(biases, variances)                                              \n",
        "  # plt.title('bias vs variance errors')                                     \n",
        "  # plt.xlabel('bias')                                                       \n",
        "  # plt.ylabel('variance')                                                   \n",
        "  # plt.show()\n",
        "\n",
        "  # plt.scatter(gammas, variances)\n",
        "  # plt.xscale('log')                                              \n",
        "  # plt.title('RBF SVM, C = 100000 \\n gamma size vs variance errors')                                     \n",
        "  # plt.xlabel('gamma')                                                       \n",
        "  # plt.ylabel('variance')                                                   \n",
        "  # plt.show()                                                            \n",
        "\n",
        "  # plt.scatter(gammas, biases)                               \n",
        "  # plt.xscale('log')                                                             \n",
        "  # plt.title('RBF SVM, C = 100000 \\n gamma size vs bias errors')                                     \n",
        "  # plt.xlabel('gamma')                                                       \n",
        "  # plt.ylabel('bias')                                                   \n",
        "  # plt.show()            \n",
        "\n",
        "  # plt.scatter(gammas, losses)                               \n",
        "  # plt.xscale('log')                                                             \n",
        "  # plt.title('RBF SVM, C = 100000 \\n gamma size vs total error')                                     \n",
        "  # plt.xlabel('gamma')                                                       \n",
        "  # plt.ylabel('error')                                                   \n",
        "  # plt.show()   \n",
        "\n",
        "  # plt.scatter(cs, biases)                               \n",
        "  # plt.xscale('log')                                                             \n",
        "  # plt.title('RBF SVM, gamma=0.1, C value vs bias errors')                                     \n",
        "  # plt.xlabel('C value')                                                       \n",
        "  # plt.ylabel('bias')                                                   \n",
        "  # plt.show()       \n",
        "\n",
        "  # plt.scatter(cs, variances)                               \n",
        "  # plt.xscale('log')                                                             \n",
        "  # plt.title('RBF SVM, gamma=0.1, C value vs variance errors')                                     \n",
        "  # plt.xlabel('C value')                                                       \n",
        "  # plt.ylabel('variance')                                                   \n",
        "  # plt.show()    \n",
        "\n",
        "  # plt.scatter(cs, losses)                               \n",
        "  # plt.xscale('log')                                                             \n",
        "  # plt.title('RBF SVM, gamma=0.1, C value vs zero-one loss')                                     \n",
        "  # plt.xlabel('C value')                                                       \n",
        "  # plt.ylabel('loss')                                                   \n",
        "  # plt.show()   \n",
        "\n",
        "  plt.scatter(biases, variances)                                              \n",
        "  plt.title('bias vs variance errors')                                     \n",
        "  plt.xlabel('bias')                                                       \n",
        "  plt.ylabel('variance')                                                   \n",
        "  plt.show()\n",
        "\n",
        "  plt.scatter(degrees, variances)\n",
        "  plt.title('poly SVM, degree size vs variance errors')                                     \n",
        "  plt.xlabel('degree')                                                       \n",
        "  plt.ylabel('variance')                                                   \n",
        "  plt.show()                                                            \n",
        "\n",
        "  plt.scatter(degrees, biases)                               \n",
        "  plt.title('poly SVM, degree size vs bias errors')                                     \n",
        "  plt.xlabel('degree')                                                       \n",
        "  plt.ylabel('bias')                                                   \n",
        "  plt.show()            \n",
        "\n",
        "  plt.scatter(degrees, losses)                               \n",
        "  plt.title('poly SVM, degree size vs generalisation errors')                                     \n",
        "  plt.xlabel('degree')                                                       \n",
        "  plt.ylabel('error')                                                   \n",
        "  plt.show()  \n",
        "\n",
        "#just an example of if we want to plot the misclassified individuals against a characteristic from the dataframe \n",
        "#might help to look for patterns \n",
        "def plot_misclassified(misclassified):\n",
        "  misclassified.reset_index().plot(kind='scatter', x='index', y='age') \n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmVUHkRN8YMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download CSV file containing all the info for the individuals who are consistently misclassified (i.e. >50% of the time, resulting in bias errors)\n",
        "def download_misclassified(misclassified, name):\n",
        "  # misclassified = np.asarray(misclassified)\n",
        "  csv_name = name+'.csv'\n",
        "  # misclassified = pd.DataFrame(misclassified)\n",
        "  print(misclassified)\n",
        "  # np.savetxt(csv_name, misclassified, delimiter=\",\")\n",
        "  misclassified.to_csv(r''+name+'.csv', index=False)\n",
        "  # from google.colab import files\n",
        "  # files.download(csv_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nbxldKcpOHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwemXVIVuhGq",
        "colab_type": "text"
      },
      "source": [
        "# Main method (execute code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vpU8QERWV4i",
        "colab_type": "text"
      },
      "source": [
        "Main method to run the system, executing methods in appropriate sequence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCBsC158supR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  all_data = load_file()\n",
        "  # demographics = ['african-american', 'caucasian', 'hispanic', 'asian', 'other', 'male', 'female', 'less than 25', '25 - 45', 'greater than 45']\n",
        "  demographics = ['african-american']\n",
        "  # demographics = [ 'hispanic', 'asian', 'other', 'male', 'female', 'less than 25', '25 - 45', 'greater than 45']\n",
        "  testing_data_and_labels_list = []\n",
        "  training_data_and_labels_list = []\n",
        "  training_data_and_labels, testing_data_and_labels = import_data(all_data)\n",
        "  training_data_and_labels_list.append(training_data_and_labels)\n",
        "  testing_data_and_labels_list.append(testing_data_and_labels)\n",
        "\n",
        "  biases = []\n",
        "  variances = []\n",
        "  total_errors = []\n",
        "  avg_losses = []\n",
        "  biases_eq = []\n",
        "  variances_eq = []\n",
        "  total_errors_eq = []\n",
        "  avg_losses_eq = []\n",
        "  classifiers, gammas, cs, degrees = define_classifiers()\n",
        "  all_misclassified = pd.DataFrame()\n",
        "  all_misclassified_eq = pd.DataFrame()\n",
        "  # misclassified = []\n",
        "  # misclassified_eq= []\n",
        "  equalised_odds = False\n",
        "  k = 0\n",
        "\n",
        "  for classifier in classifiers:\n",
        "    print(classifier)\n",
        "    # clf = classifiers[classifier_names.index(classifier)]\n",
        "    clf = classifier\n",
        "    for i in range(len(training_data_and_labels_list)):\n",
        "      # print('testing ', demographics[i], '=', true_case)\n",
        "      predictions, true_labels, soft_scores = classify(training_data_and_labels_list[i], testing_data_and_labels_list[i], clf)  \n",
        "      # predictions, true_labels = classify_noise(training_data_and_labels_list[i], testing_data_and_labels_list[i], clf)\n",
        "      # noise_predictions = predictions\n",
        "      soft_scores = calculate_scores(predictions, soft_scores)\n",
        "      majority_predictions = predictions.mode(numeric_only=True)\n",
        "      calc_fairness_metrics(true_labels, majority_predictions)\n",
        "      if(equalised_odds):\n",
        "        for demographic in demographics:\n",
        "          group_ids = [] \n",
        "          print(\"Equalising odds for \", demographic)\n",
        "          group_ids_normalised = testing_data_and_labels[demographic]\n",
        "          for n_id in group_ids_normalised:\n",
        "            group_id = 0 if n_id < 0 else 1\n",
        "            group_ids.append(group_id)\n",
        "          group_ids = pd.DataFrame([group_ids])\n",
        "          all_eq_predictions = []\n",
        "          for j in range (len(predictions.index)):\n",
        "            eq_predictions, true_eq_labels = constrain_with_equalised_odds(true_labels, group_ids, demographic, soft_scores)\n",
        "            all_eq_predictions.append(np.array(eq_predictions))\n",
        "          all_eq_predictions = pd.DataFrame(all_eq_predictions)\n",
        "          true_eq_labels = pd.DataFrame(np.array(true_eq_labels), columns=['two_year_recid'])\n",
        "          true_eq_labels = true_eq_labels.transpose()\n",
        "      print(\"before fairness correction:\")\n",
        "      #if not equalised odds we have to only use half of the predictions somehow otherwise it's not fair \n",
        "      #because in equalised odds we use half of it to determine parameters (validation)\n",
        "      # print(predictions)\n",
        "      if(equalised_odds):\n",
        "        predictions = predictions.iloc[:,:int(len(predictions.columns)/2)]\n",
        "        true_labels = true_labels.iloc[:,:int(len(true_labels.columns)/2)]\n",
        "      # noise_predictions = noise_predictions.iloc[:,:int(len(predictions.columns)/2)]\n",
        "      # print(predictions)\n",
        "      # fake_predictions = predictions.replace(predictions, 0)\n",
        "      # fake_true_labels = true_labels.replace(true_labels, 1)\n",
        "      bias, variance, avg_loss, misclassified_individuals = compute_bias_variance(predictions, true_labels)\n",
        "      biases.append(bias)\n",
        "      variances.append(variance)\n",
        "      avg_losses.append(avg_loss)\n",
        "      if(equalised_odds):\n",
        "        print(\"after fairness correction:\")\n",
        "        bias_eq, variance_eq, avg_loss_eq, misclassified_individuals_eq = compute_bias_variance(all_eq_predictions, true_eq_labels)\n",
        "        biases_eq.append(bias_eq)\n",
        "        variances_eq.append(variance_eq)\n",
        "        avg_losses_eq.append(avg_loss_eq)\n",
        "      #get the individuals which are misclassified on average (hence contributing to bias errors)\n",
        "      print(\"misclassified before: \", misclassified_individuals)\n",
        "      if(equalised_odds):\n",
        "        print(\"misclassified after: \", misclassified_individuals_eq)\n",
        "      for i in range(len(testing_data_and_labels_list)):\n",
        "        if(len(misclassified_individuals) > 0 ):\n",
        "          misclassified = testing_data_and_labels_list[i].iloc[misclassified_individuals]\n",
        "          # print(misclassified)\n",
        "          all_misclassified = all_misclassified.append(misclassified)\n",
        "          # all_misclassified = pd.concat(all_misclassified, misclassified)\n",
        "        if(equalised_odds):\n",
        "          if(len(misclassified_individuals_eq) > 0):\n",
        "            misclassified_eq = testing_data_and_labels_list[i].iloc[misclassified_individuals_eq]\n",
        "            # all_misclassified_eq = pd.concat(all_misclassified_eq, misclassified_eq)\n",
        "            all_misclassified_eq = all_misclassified_eq.append(misclassified_eq)\n",
        "      download_misclassified(all_misclassified, str(k)+'_misclassified_before')\n",
        "      if(equalised_odds):\n",
        "        download_misclassified(all_misclassified_eq, str(k)+'_misclassified_after')\n",
        "      k+=1\n",
        "      # plot_misclassified(misclassified)\n",
        "      \n",
        "  print(\"before fairness correction:\")\n",
        "  plot_bias_variance(biases, variances, gammas, cs, degrees, avg_losses)\n",
        "  if(equalised_odds):\n",
        "    print(\"after fairness correction:\")\n",
        "    plot_bias_variance(biases_eq, variances_eq, gammas, cs, degrees, avg_losses_eq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA8uQhlb8ARv",
        "colab_type": "code",
        "outputId": "87b21520-a8c9-4f1c-9e99-44e8bae87ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data\n",
            "loaded data\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 862 rate: 0.53875 false positives: 38 rate: 0.02375 false negatives: 36 rate: 0.0225 true positives: 664 rate: 0.415\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.064296875\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.04625\n",
            "average variance:\n",
            "0.0391375\n",
            "misclassified before:  [12, 26, 27, 57, 89, 101, 141, 163, 166, 195, 206, 224, 233, 246, 259, 321, 353, 361, 374, 403, 409, 454, 466, 574, 581, 606, 648, 666, 688, 759, 832, 845, 849, 865, 891, 896, 915, 916, 935, 954, 958, 975, 983, 986, 997, 998, 1029, 1037, 1041, 1050, 1063, 1090, 1099, 1100, 1109, 1144, 1201, 1205, 1228, 1245, 1319, 1330, 1404, 1416, 1425, 1442, 1447, 1462, 1480, 1493, 1495, 1517, 1519, 1569]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1493      -0.114991        1.749043  ... -0.080906               0\n",
            "1495      -0.114991       -0.181568  ... -0.080906               1\n",
            "1517      -0.114991       -0.181568  ... -0.080906               0\n",
            "1519      -0.114991       -0.181568  ... -0.080906               1\n",
            "1569      -0.114991       -0.181568  ... -0.080906               1\n",
            "\n",
            "[74 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.005, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 857 rate: 0.535625 false positives: 43 rate: 0.026875 false negatives: 27 rate: 0.016875 true positives: 673 rate: 0.420625\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.07257343749999999\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.04375\n",
            "average variance:\n",
            "0.0494734375\n",
            "misclassified before:  [12, 26, 27, 69, 81, 101, 141, 163, 165, 195, 233, 246, 259, 299, 334, 353, 361, 402, 403, 409, 425, 454, 466, 574, 581, 606, 648, 666, 688, 755, 759, 764, 793, 832, 845, 849, 891, 916, 935, 958, 975, 983, 986, 998, 1029, 1037, 1050, 1063, 1090, 1099, 1100, 1109, 1144, 1201, 1205, 1228, 1239, 1319, 1330, 1404, 1416, 1424, 1425, 1442, 1447, 1462, 1480, 1493, 1495, 1569]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1462      -0.114991       -0.181568  ... -0.080906               0\n",
            "1480      -0.114991       -0.181568  ... -0.080906               1\n",
            "1493      -0.114991        1.749043  ... -0.080906               0\n",
            "1495      -0.114991       -0.181568  ... -0.080906               1\n",
            "1569      -0.114991       -0.181568  ... -0.080906               1\n",
            "\n",
            "[144 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 857 rate: 0.535625 false positives: 43 rate: 0.026875 false negatives: 24 rate: 0.015 true positives: 676 rate: 0.4225\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.0711578125\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.041875\n",
            "average variance:\n",
            "0.048648437499999996\n",
            "misclassified before:  [12, 26, 27, 69, 81, 101, 141, 163, 165, 191, 195, 233, 246, 259, 299, 304, 334, 353, 361, 381, 402, 403, 409, 425, 454, 466, 530, 542, 574, 606, 648, 666, 688, 755, 759, 793, 832, 845, 849, 891, 935, 958, 975, 983, 986, 998, 1029, 1037, 1050, 1063, 1090, 1100, 1109, 1144, 1201, 1205, 1228, 1330, 1416, 1424, 1425, 1447, 1462, 1480, 1493, 1495, 1569]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1462      -0.114991       -0.181568  ... -0.080906               0\n",
            "1480      -0.114991       -0.181568  ... -0.080906               1\n",
            "1493      -0.114991        1.749043  ... -0.080906               0\n",
            "1495      -0.114991       -0.181568  ... -0.080906               1\n",
            "1569      -0.114991       -0.181568  ... -0.080906               1\n",
            "\n",
            "[211 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 848 rate: 0.53 false positives: 52 rate: 0.0325 false negatives: 20 rate: 0.0125 true positives: 680 rate: 0.425\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.05770468749999999\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.045\n",
            "average variance:\n",
            "0.028704687500000003\n",
            "misclassified before:  [12, 26, 27, 69, 81, 101, 163, 195, 203, 206, 228, 246, 259, 265, 334, 353, 361, 367, 402, 403, 409, 425, 437, 466, 470, 530, 542, 574, 606, 610, 648, 666, 759, 764, 793, 805, 832, 845, 849, 885, 891, 935, 958, 975, 983, 986, 998, 1029, 1037, 1050, 1063, 1090, 1096, 1100, 1109, 1144, 1201, 1205, 1330, 1414, 1416, 1424, 1425, 1442, 1447, 1462, 1480, 1493, 1495, 1517, 1533, 1590]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1493      -0.114991        1.749043  ... -0.080906               0\n",
            "1495      -0.114991       -0.181568  ... -0.080906               1\n",
            "1517      -0.114991       -0.181568  ... -0.080906               0\n",
            "1533      -0.114991       -0.181568  ... -0.080906               1\n",
            "1590      -0.114991       -0.181568  ... -0.080906               1\n",
            "\n",
            "[283 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 844 rate: 0.5275 false positives: 56 rate: 0.035 false negatives: 15 rate: 0.009375 true positives: 685 rate: 0.428125\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.05143906250000001\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.044375\n",
            "average variance:\n",
            "0.0169046875\n",
            "misclassified before:  [12, 26, 27, 69, 81, 101, 163, 195, 203, 206, 228, 259, 265, 334, 361, 367, 402, 409, 425, 437, 466, 470, 530, 542, 574, 606, 610, 648, 666, 759, 764, 793, 805, 832, 845, 849, 862, 885, 891, 896, 907, 935, 958, 975, 983, 986, 998, 1029, 1037, 1050, 1063, 1096, 1100, 1109, 1144, 1192, 1201, 1205, 1228, 1297, 1330, 1416, 1424, 1425, 1442, 1447, 1462, 1480, 1493, 1495, 1533]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1462      -0.114991       -0.181568  ... -0.080906               0\n",
            "1480      -0.114991       -0.181568  ... -0.080906               1\n",
            "1493      -0.114991        1.749043  ... -0.080906               0\n",
            "1495      -0.114991       -0.181568  ... -0.080906               1\n",
            "1533      -0.114991       -0.181568  ... -0.080906               1\n",
            "\n",
            "[354 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 792 rate: 0.495 false positives: 108 rate: 0.0675 false negatives: 8 rate: 0.005 true positives: 692 rate: 0.4325\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.09118281249999999\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.0725\n",
            "average variance:\n",
            "0.0283953125\n",
            "misclassified before:  [12, 26, 27, 42, 69, 81, 101, 152, 163, 172, 176, 185, 189, 195, 203, 206, 228, 244, 259, 265, 290, 316, 334, 347, 361, 367, 371, 402, 409, 415, 425, 428, 437, 466, 470, 542, 568, 573, 574, 596, 606, 610, 640, 648, 657, 666, 667, 671, 749, 759, 793, 799, 845, 849, 852, 854, 862, 876, 885, 891, 896, 907, 919, 927, 935, 958, 975, 983, 986, 990, 998, 1005, 1011, 1017, 1029, 1037, 1038, 1050, 1060, 1063, 1071, 1096, 1100, 1109, 1144, 1176, 1190, 1192, 1201, 1204, 1205, 1227, 1228, 1241, 1247, 1297, 1319, 1378, 1396, 1406, 1416, 1424, 1425, 1435, 1442, 1447, 1462, 1480, 1490, 1493, 1512, 1517, 1541, 1559, 1572, 1582]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1517      -0.114991       -0.181568  ... -0.080906               0\n",
            "1541      -0.114991        1.749043  ... -0.080906               0\n",
            "1559      -0.114991       -0.181568  ... -0.080906               0\n",
            "1572      -0.114991        1.749043  ... -0.080906               0\n",
            "1582      -0.114991       -0.181568  ... -0.080906               0\n",
            "\n",
            "[470 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
            "    probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 758 rate: 0.47375 false positives: 142 rate: 0.08875 false negatives: 8 rate: 0.005 true positives: 692 rate: 0.4325\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.11085468750000001\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.09375\n",
            "average variance:\n",
            "0.0238953125\n",
            "misclassified before:  [12, 18, 26, 27, 42, 47, 69, 81, 101, 135, 152, 163, 172, 176, 185, 189, 195, 201, 203, 206, 219, 228, 242, 244, 259, 265, 290, 310, 316, 334, 347, 361, 367, 371, 402, 409, 415, 425, 428, 437, 448, 466, 470, 542, 550, 560, 568, 569, 573, 574, 596, 605, 606, 610, 617, 640, 643, 648, 652, 657, 666, 667, 671, 690, 692, 749, 759, 766, 780, 788, 793, 799, 845, 849, 852, 854, 862, 866, 876, 885, 891, 896, 907, 908, 919, 927, 929, 935, 958, 975, 983, 986, 990, 995, 998, 1004, 1005, 1011, 1017, 1029, 1037, 1038, 1046, 1050, 1060, 1063, 1071, 1096, 1100, 1109, 1144, 1176, 1183, 1190, 1192, 1201, 1204, 1205, 1227, 1228, 1241, 1247, 1297, 1312, 1319, 1336, 1374, 1378, 1396, 1406, 1416, 1424, 1425, 1435, 1436, 1442, 1447, 1450, 1462, 1480, 1490, 1493, 1511, 1512, 1517, 1541, 1542, 1559, 1572, 1582]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1541      -0.114991        1.749043  ... -0.080906               0\n",
            "1542      -0.114991       -0.181568  ... -0.080906               0\n",
            "1559      -0.114991       -0.181568  ... -0.080906               0\n",
            "1572      -0.114991        1.749043  ... -0.080906               0\n",
            "1582      -0.114991       -0.181568  ... -0.080906               0\n",
            "\n",
            "[620 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=5, kernel='rbf', max_iter=-1,\n",
            "    probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 728 rate: 0.455 false positives: 172 rate: 0.1075 false negatives: 6 rate: 0.00375 true positives: 694 rate: 0.43375\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.1311484375\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.11125\n",
            "average variance:\n",
            "0.026160937500000002\n",
            "misclassified before:  [12, 18, 26, 27, 42, 47, 69, 81, 101, 131, 135, 152, 163, 172, 176, 185, 189, 195, 201, 203, 206, 213, 219, 228, 242, 244, 259, 265, 267, 269, 286, 290, 310, 311, 316, 334, 347, 361, 367, 371, 402, 407, 409, 415, 425, 428, 437, 448, 466, 470, 473, 542, 550, 560, 568, 569, 573, 574, 596, 605, 606, 610, 617, 638, 640, 643, 648, 652, 657, 666, 667, 671, 680, 690, 692, 698, 701, 749, 759, 766, 778, 780, 788, 793, 794, 799, 845, 849, 850, 852, 854, 862, 866, 876, 885, 891, 903, 907, 908, 919, 927, 929, 935, 948, 958, 969, 975, 983, 986, 990, 995, 998, 1004, 1005, 1011, 1017, 1029, 1034, 1037, 1038, 1046, 1050, 1060, 1063, 1071, 1089, 1096, 1100, 1109, 1119, 1144, 1176, 1183, 1190, 1192, 1201, 1204, 1205, 1227, 1228, 1241, 1247, 1278, 1297, 1312, 1319, 1336, 1344, 1347, 1368, 1374, 1378, 1393, 1396, 1406, 1416, 1420, 1424, 1425, 1435, 1436, 1447, 1450, 1458, 1462, 1480, 1490, 1493, 1506, 1511, 1512, 1517, 1541, 1542, 1559, 1572, 1582, 1587]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1542      -0.114991       -0.181568  ... -0.080906               0\n",
            "1559      -0.114991       -0.181568  ... -0.080906               0\n",
            "1572      -0.114991        1.749043  ... -0.080906               0\n",
            "1582      -0.114991       -0.181568  ... -0.080906               0\n",
            "1587      -0.114991       -0.181568  ... -0.080906               0\n",
            "\n",
            "[798 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 723 rate: 0.451875 false positives: 177 rate: 0.110625 false negatives: 5 rate: 0.003125 true positives: 695 rate: 0.434375\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.1395890625\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.11375\n",
            "average variance:\n",
            "0.028229687500000003\n",
            "misclassified before:  [12, 18, 26, 27, 42, 47, 61, 69, 81, 101, 113, 131, 135, 152, 163, 172, 176, 185, 189, 195, 201, 203, 206, 213, 219, 228, 242, 244, 259, 265, 267, 269, 286, 290, 310, 311, 316, 334, 347, 361, 367, 371, 402, 407, 409, 415, 425, 428, 433, 437, 448, 466, 470, 473, 542, 544, 550, 560, 568, 569, 573, 574, 596, 605, 606, 610, 617, 638, 640, 643, 648, 652, 657, 667, 671, 680, 690, 692, 698, 701, 749, 759, 766, 778, 780, 788, 793, 794, 799, 845, 849, 850, 852, 854, 862, 866, 876, 885, 891, 903, 907, 908, 919, 927, 929, 935, 948, 958, 969, 975, 983, 986, 990, 995, 998, 1004, 1005, 1011, 1017, 1029, 1034, 1037, 1038, 1046, 1050, 1060, 1063, 1071, 1089, 1096, 1100, 1109, 1119, 1144, 1176, 1183, 1190, 1192, 1201, 1204, 1205, 1227, 1228, 1241, 1247, 1278, 1297, 1312, 1319, 1336, 1344, 1347, 1357, 1368, 1374, 1378, 1393, 1396, 1406, 1416, 1420, 1424, 1425, 1435, 1436, 1447, 1450, 1458, 1462, 1480, 1490, 1493, 1506, 1511, 1512, 1517, 1541, 1542, 1559, 1572, 1582, 1587]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1542      -0.114991       -0.181568  ... -0.080906               0\n",
            "1559      -0.114991       -0.181568  ... -0.080906               0\n",
            "1572      -0.114991        1.749043  ... -0.080906               0\n",
            "1582      -0.114991       -0.181568  ... -0.080906               0\n",
            "1587      -0.114991       -0.181568  ... -0.080906               0\n",
            "\n",
            "[980 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=50, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 683 rate: 0.426875 false positives: 217 rate: 0.135625 false negatives: 3 rate: 0.001875 true positives: 697 rate: 0.435625\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.2301828125\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.1375\n",
            "average variance:\n",
            "0.16999218749999997\n",
            "misclassified before:  [2, 11, 12, 17, 18, 22, 26, 27, 42, 47, 54, 61, 69, 81, 100, 101, 113, 131, 135, 152, 163, 172, 176, 185, 189, 195, 201, 203, 213, 219, 228, 242, 244, 259, 265, 267, 269, 286, 290, 310, 311, 316, 326, 334, 341, 347, 361, 364, 367, 371, 401, 402, 407, 409, 415, 425, 428, 433, 437, 439, 448, 466, 470, 473, 501, 542, 544, 550, 558, 560, 568, 569, 573, 574, 575, 592, 596, 605, 606, 610, 617, 638, 640, 641, 643, 648, 652, 657, 667, 671, 680, 682, 690, 692, 696, 698, 701, 745, 749, 754, 759, 766, 772, 778, 780, 788, 793, 794, 799, 825, 831, 845, 849, 850, 852, 854, 862, 866, 876, 885, 891, 903, 907, 908, 918, 919, 927, 929, 935, 943, 948, 956, 958, 969, 975, 983, 986, 990, 993, 995, 998, 1004, 1005, 1011, 1017, 1029, 1034, 1037, 1038, 1046, 1050, 1060, 1063, 1071, 1082, 1089, 1096, 1100, 1109, 1119, 1144, 1176, 1183, 1190, 1192, 1201, 1204, 1205, 1227, 1228, 1241, 1247, 1250, 1254, 1278, 1297, 1300, 1312, 1317, 1319, 1336, 1340, 1344, 1347, 1357, 1358, 1368, 1374, 1378, 1393, 1396, 1406, 1416, 1420, 1424, 1425, 1435, 1436, 1447, 1450, 1458, 1462, 1470, 1472, 1490, 1493, 1503, 1506, 1511, 1512, 1513, 1517, 1525, 1541, 1542, 1559, 1564, 1572, 1582, 1587]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1559      -0.114991       -0.181568  ... -0.080906               0\n",
            "1564      -0.114991       -0.181568  ... -0.080906               0\n",
            "1572      -0.114991        1.749043  ... -0.080906               0\n",
            "1582      -0.114991       -0.181568  ... -0.080906               0\n",
            "1587      -0.114991       -0.181568  ... -0.080906               0\n",
            "\n",
            "[1200 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=100, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 683 rate: 0.426875 false positives: 217 rate: 0.135625 false negatives: 3 rate: 0.001875 true positives: 697 rate: 0.435625\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.3130890625\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.1375\n",
            "average variance:\n",
            "0.2967953125\n",
            "misclassified before:  [2, 11, 12, 17, 18, 22, 26, 27, 42, 47, 54, 61, 69, 81, 100, 101, 113, 131, 135, 152, 163, 172, 176, 185, 189, 195, 201, 203, 213, 219, 228, 242, 244, 259, 265, 267, 269, 286, 290, 310, 311, 316, 326, 334, 341, 347, 361, 364, 367, 371, 401, 402, 407, 409, 415, 425, 428, 433, 437, 439, 448, 466, 470, 473, 501, 542, 544, 550, 558, 560, 568, 569, 573, 574, 575, 592, 596, 605, 606, 610, 617, 638, 640, 641, 643, 648, 652, 657, 667, 671, 680, 682, 690, 692, 696, 698, 701, 745, 749, 754, 759, 766, 772, 778, 780, 788, 793, 794, 799, 825, 831, 845, 849, 850, 852, 854, 862, 866, 876, 885, 891, 903, 907, 908, 918, 919, 927, 929, 935, 943, 948, 956, 958, 969, 975, 983, 986, 990, 993, 995, 998, 1004, 1005, 1011, 1017, 1029, 1034, 1037, 1038, 1046, 1050, 1060, 1063, 1071, 1082, 1089, 1096, 1100, 1109, 1119, 1144, 1176, 1183, 1190, 1192, 1201, 1204, 1205, 1227, 1228, 1241, 1247, 1250, 1254, 1278, 1297, 1300, 1312, 1317, 1319, 1336, 1340, 1344, 1347, 1357, 1358, 1368, 1374, 1378, 1393, 1396, 1406, 1416, 1420, 1424, 1425, 1435, 1436, 1447, 1450, 1458, 1462, 1470, 1472, 1490, 1493, 1503, 1506, 1511, 1512, 1513, 1517, 1525, 1541, 1542, 1559, 1564, 1572, 1582, 1587]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1559      -0.114991       -0.181568  ... -0.080906               0\n",
            "1564      -0.114991       -0.181568  ... -0.080906               0\n",
            "1572      -0.114991        1.749043  ... -0.080906               0\n",
            "1582      -0.114991       -0.181568  ... -0.080906               0\n",
            "1587      -0.114991       -0.181568  ... -0.080906               0\n",
            "\n",
            "[1420 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=500, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "true negatives: 549 rate: 0.343125 false positives: 351 rate: 0.219375 false negatives: 2 rate: 0.00125 true positives: 698 rate: 0.43625\n",
            "before fairness correction:\n",
            "average loss:\n",
            "0.32975781249999997\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.220625\n",
            "average variance:\n",
            "0.30897343749999995\n",
            "misclassified before:  [0, 2, 6, 11, 12, 14, 17, 18, 22, 26, 27, 30, 36, 42, 47, 49, 54, 61, 63, 64, 69, 72, 76, 81, 84, 100, 101, 105, 106, 107, 108, 113, 117, 131, 135, 152, 159, 160, 163, 170, 172, 176, 180, 185, 188, 189, 195, 201, 203, 211, 213, 219, 220, 228, 229, 232, 239, 242, 244, 245, 248, 259, 262, 265, 266, 267, 268, 269, 276, 282, 286, 288, 290, 301, 310, 311, 316, 325, 326, 327, 333, 341, 347, 361, 364, 367, 371, 377, 380, 388, 394, 401, 402, 407, 409, 415, 422, 425, 428, 433, 437, 439, 445, 448, 466, 470, 473, 487, 491, 501, 505, 506, 518, 525, 542, 544, 550, 553, 558, 559, 560, 568, 569, 573, 574, 575, 579, 580, 588, 592, 593, 596, 605, 606, 609, 610, 612, 617, 631, 638, 640, 641, 643, 648, 652, 657, 664, 667, 671, 676, 680, 682, 690, 692, 693, 696, 698, 701, 704, 727, 732, 736, 745, 749, 754, 759, 762, 766, 769, 772, 778, 780, 788, 789, 793, 794, 799, 810, 825, 831, 836, 844, 845, 849, 850, 852, 854, 862, 866, 869, 872, 875, 876, 885, 891, 893, 899, 903, 907, 908, 917, 918, 919, 927, 929, 935, 937, 943, 948, 949, 956, 958, 961, 962, 969, 972, 973, 975, 983, 986, 990, 993, 995, 998, 1004, 1005, 1011, 1012, 1017, 1024, 1029, 1032, 1034, 1037, 1038, 1046, 1048, 1050, 1059, 1060, 1063, 1064, 1068, 1071, 1079, 1080, 1081, 1082, 1086, 1089, 1096, 1098, 1100, 1105, 1109, 1114, 1115, 1119, 1127, 1139, 1142, 1144, 1151, 1152, 1162, 1176, 1181, 1183, 1190, 1192, 1201, 1203, 1204, 1205, 1221, 1227, 1228, 1241, 1243, 1247, 1250, 1254, 1258, 1273, 1278, 1297, 1300, 1302, 1312, 1317, 1319, 1323, 1327, 1336, 1340, 1344, 1347, 1353, 1357, 1358, 1366, 1368, 1372, 1373, 1374, 1378, 1379, 1387, 1391, 1393, 1396, 1406, 1408, 1416, 1420, 1424, 1425, 1435, 1436, 1447, 1450, 1458, 1459, 1462, 1463, 1466, 1470, 1472, 1475, 1487, 1490, 1493, 1497, 1503, 1506, 1511, 1512, 1513, 1517, 1525, 1531, 1536, 1541, 1542, 1556, 1559, 1564, 1565, 1572, 1582, 1587, 1588, 1593]\n",
            "      juv_fel_count  juv_misd_count  ...     (mo3)  two_year_recid\n",
            "12        -0.114991        1.749043  ... -0.080906               0\n",
            "26        -0.114991       -0.181568  ... -0.080906               0\n",
            "27        -0.114991       -0.181568  ... -0.080906               0\n",
            "57        -0.114991        1.749043  ... -0.080906               1\n",
            "89         1.550712       11.402097  ... -0.080906               1\n",
            "...             ...             ...  ...       ...             ...\n",
            "1572      -0.114991        1.749043  ... -0.080906               0\n",
            "1582      -0.114991       -0.181568  ... -0.080906               0\n",
            "1587      -0.114991       -0.181568  ... -0.080906               0\n",
            "1588      -0.114991       -0.181568  ... -0.080906               0\n",
            "1593      -0.114991       -0.181568  ... -0.080906               0\n",
            "\n",
            "[1773 rows x 28 columns]\n",
            "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=1000, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOTgKGG1bVwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}