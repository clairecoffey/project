{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "claire_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clairecoffey/project/blob/master/claire_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep76GcW0r5EF",
        "colab_type": "text"
      },
      "source": [
        "# Fairness and the Bias/Variance Tradeoff \n",
        "\n",
        "## Claire Coffey\n",
        "\n",
        "## May 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt8eZN7L71OB",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we are studying bias and variance errors in the context of fairness, by exploring recidivism data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5j4K9fEtccc",
        "colab_type": "text"
      },
      "source": [
        "## Imports and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwPz0FbDrdOB",
        "colab_type": "text"
      },
      "source": [
        "Imports: first import the relevant libraries used throughout. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3xUTfnrkM0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojFZOY-LtsdL",
        "colab_type": "text"
      },
      "source": [
        "# Read in recidivism data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLIFxjZ9roCK",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we are studying recidivism data. We utilise the COMPAS recidivism dataset, which uses recidivism data from Broward County jail and has been explored in the following studies:\n",
        "\n",
        "\"The accuracy, fairness, and limits of predicting recidivism\", paper available at:\n",
        "https://advances.sciencemag.org/content/4/1/eaao5580#corresp-1\n",
        "\n",
        "\"Machine Bias\" ProPublica article, available at:\n",
        "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n",
        "\n",
        "The dataset used can be found at:\n",
        "https://github.com/propublica/compas-analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmO2E_MbHUGY",
        "colab_type": "text"
      },
      "source": [
        "Here we import and read in the recidivism data. Currently, we are using a selection of 1000 samples from this dataset for our predictions (the first 1000 samples of the dataset)\n",
        "\n",
        "We use a selection \n",
        "of fields from this dataset to predict recidivism classification (0 = will reoffend (negative case); 1 = will not reoffend (positive case))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdCKnj1kqViI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_file():\n",
        "  full_data = False\n",
        "  print(\"loading data\")\n",
        "  if full_data:\n",
        "    # full dataset\n",
        "    file_path = \"https://raw.githubusercontent.com/clairecoffey/project/master/mphilproject/compas-scores-two-years%20-%20compas-scores-two-years.csv?token=ABPC6VNTFTGQBANNUJY2O4C6XGJGY\"\n",
        "  else:\n",
        "    # small subset of first 500/1000 people\n",
        "    file_path = \"https://raw.githubusercontent.com/clairecoffey/project/master/mphilproject/500-compas-scores-two-years%20-%20Sheet1%20(1).csv?token=ABPC6VOW7CBEIIGZVE6ZJYS6YKNHO\"\n",
        "    # file_path = \"https://raw.githubusercontent.com/clairecoffey/project/master/mphilproject/1000-compas-scores-two-years%20-%20Sheet1.csv\"\n",
        "\n",
        "  # load CSV contents\n",
        "  all_data = pd.read_csv(file_path, delimiter=',', dtype={'sex': 'category', \n",
        "                                                          'age_cat': 'category',\n",
        "                                                          'race': 'category',\n",
        "                                                          'c_charge_degree': 'category',\n",
        "                                                          'c_charge_desc': 'category',\n",
        "                                                          'r_charge_degree': 'category',\n",
        "                                                          'r_charge_desc': 'category',\n",
        "                                                          'vr_charge_degree': 'category',\n",
        "                                                          'vr_charge_desc': 'category'\n",
        "                                                          })\n",
        "  print('loaded data')\n",
        "  return all_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1WpLQEMZUNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all_data = load_file()\n",
        "# all_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19AV7fOG0z4h",
        "colab_type": "text"
      },
      "source": [
        "## Import and process data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB8DQVf7g1Nn",
        "colab_type": "text"
      },
      "source": [
        "We import the data into a pandas DataFrame. We begin by cleaning the data, so the crime descriptions are simplified, removing duplicate categories. For example, we merge descriptions such as 'possession of cocaine' and 'possess cocaine', or 'burglary/weapon' and 'burglary and weapon', by removing prepositions, and replacing abreviations and similies. \n",
        "\n",
        "Then,  the categorical data is  split into different fields for each category, and encoded as 0 or 1. For example, an individual with characteristic \"sex: male\" would be encoded as \"male: 1, female: 0\". The sex category is then removed.\n",
        "\n",
        "We then consider which fields to use for prediction. This includes the removal of any fields/columns which contain many NaN values, since these cannot be handled by the classifiers. We choose to remove the columns with many NaNs rather than using an alternative approach such as replacing them with the average so as not to introduce other types of bias. We also then remove rows/individuals containing any further NaN values so there is no longer any NaN values present in the data. \n",
        "\n",
        "We then normalise all of the data in the dataframe, so that when fed into the classifier, the predicitons are not skewed (and potentially different forms of bias introduced).  We do this by using the StandardScaler in the sklearn preprocessing library, and we normalise the data to have a variance of 1.\n",
        "\n",
        "Finally, we define the number of testing/training samples desired and split the data into these two sets appropriately.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzJytmnMtkPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def clean_descriptions(description):\n",
        "  description = description.replace(' and ', ' ')\n",
        "  description = description.replace(' / ', ' ')\n",
        "  description = description.replace('possession', 'posess')\n",
        "  description = description.replace('possessing', 'posess')\n",
        "  description = description.replace('with', 'w/')\n",
        "  description = description.replace('w/ ', 'w/')\n",
        "  description = description.replace('w/', ' ')\n",
        "  description = description.replace('attempted', 'att')\n",
        "  description = description.replace('attempt', 'att')\n",
        "  description = description.replace('aggravated', 'agg')\n",
        "  description = description.replace('aggrav', 'agg') \n",
        "  description = description.replace(' of ', ' ')\n",
        "  return description\n",
        "\n",
        "def import_data(all_data):\n",
        "  num_testing_samples = 201\n",
        "\n",
        "  encoded_sex = (pd.get_dummies(all_data['sex']))\n",
        "  all_data = all_data.drop(columns=['sex'])\n",
        "  all_data = all_data.join(encoded_sex)\n",
        "\n",
        "  encoded_age_cat = (pd.get_dummies(all_data['age_cat']))\n",
        "  all_data = all_data.drop(columns=['age_cat'])\n",
        "  all_data = all_data.join(encoded_age_cat)\n",
        "\n",
        "  encoded_race = (pd.get_dummies(all_data['race']))\n",
        "  all_data = all_data.drop(columns=['race'])\n",
        "  all_data = all_data.join(encoded_race)\n",
        "\n",
        "  encoded_c_charge_degree = (pd.get_dummies(all_data['c_charge_degree']))\n",
        "  all_data = all_data.drop(columns=['c_charge_degree'])\n",
        "  all_data = all_data.join(encoded_c_charge_degree, rsuffix='_c')\n",
        "\n",
        "  #these are joined with suffixes because otherwise columns overlap \n",
        "  all_data['c_charge_desc'] = all_data['c_charge_desc'].astype(str).str.lower()\n",
        "  all_data['c_charge_desc'] = all_data['c_charge_desc'].apply(clean_descriptions)\n",
        "  encoded_c_charge_desc = (pd.get_dummies(all_data['c_charge_desc']))\n",
        "  all_data = all_data.drop(columns=['c_charge_desc'])\n",
        "  all_data = all_data.join(encoded_c_charge_desc, rsuffix='_c')\n",
        "\n",
        "  encoded_r_charge_degree = (pd.get_dummies(all_data['r_charge_degree']))\n",
        "  all_data = all_data.drop(columns=['r_charge_degree'])\n",
        "  all_data = all_data.join(encoded_r_charge_degree, rsuffix='_r')\n",
        "\n",
        "  all_data['r_charge_desc'] = all_data['r_charge_desc'].astype(str).str.lower()\n",
        "  all_data['r_charge_desc'] = all_data['r_charge_desc'].apply(clean_descriptions)\n",
        "  encoded_r_charge_desc = (pd.get_dummies(all_data['r_charge_desc']))\n",
        "  all_data = all_data.drop(columns=['r_charge_desc'])\n",
        "  all_data = all_data.join(encoded_r_charge_desc, rsuffix='_r')\n",
        "\n",
        "  encoded_vr_charge_degree = (pd.get_dummies(all_data['vr_charge_degree']))\n",
        "  all_data = all_data.drop(columns=['vr_charge_degree'])\n",
        "  all_data = all_data.join(encoded_vr_charge_degree, rsuffix='_vr')\n",
        "\n",
        "  all_data['vr_charge_desc'] = all_data['vr_charge_desc'].astype(str).str.lower()\n",
        "  all_data['vr_charge_desc'] = all_data['vr_charge_desc'].apply(clean_descriptions)\n",
        "  encoded_vr_charge_desc = (pd.get_dummies(all_data['vr_charge_desc']))\n",
        "  all_data = all_data.drop(columns=['vr_charge_desc'])\n",
        "  all_data = all_data.join(encoded_vr_charge_desc, rsuffix='_vr')\n",
        "\n",
        "  all_data = all_data.drop(columns=['nan'])\n",
        "  all_data = all_data.drop(columns=['nan_vr'])\n",
        "  all_data = all_data.drop(columns=['nan_r'])\n",
        "\n",
        "  #swap the 1s and 0s in 'two_year_recid', because we want \"1\" to refer to the positive case, i.e. did not reoffend\n",
        "  #this helps later on with our fairness definitions and calculations\n",
        "  # two_year_recid_swapped = pd.DataFrame(np.logical_xor(all_data['two_year_recid'].values,1).astype(int), columns=['two_year_recid_swapped'])\n",
        "  # all_data = all_data.drop(columns=['two_year_recid'])\n",
        "  # all_data = all_data.join(two_year_recid_swapped)\n",
        "\n",
        "  #drop columns not used for predictions, including info such as names, and coluns with many NaN values \n",
        "  all_data_simplified = all_data.drop(columns=['two_year_recid', 'r_days_from_arrest', 'id','name','first','last','dob','days_b_screening_arrest','c_jail_in','c_jail_out','c_case_number','c_offense_date','c_arrest_date','r_case_number','r_offense_date','r_jail_in','r_jail_out','vr_case_number','vr_offense_date','in_custody','out_custody','start','end','violent_recid', 'age'])\n",
        "\n",
        "  #remove rows containing NaN values \n",
        "  all_data_simplified = all_data_simplified.dropna()\n",
        "\n",
        "  #Renormalise the data so we have unit variance and mean 0 using built-in preprocessing method in sklearn\n",
        "  scaler = preprocessing.StandardScaler()\n",
        "  all_data_scaled = pd.DataFrame(scaler.fit_transform(all_data_simplified),columns=all_data_simplified.columns)\n",
        "\n",
        "  all_data_and_labels = all_data_scaled.join(all_data[['two_year_recid']])\n",
        "  all_data_and_labels.columns = map(str.lower, all_data_and_labels.columns)\n",
        "\n",
        "  #split into training and testing with specific number of testing samples\n",
        "  #for now just set testing set to be first num_testing_samples samples in table \n",
        "  testing_data_and_labels = all_data_and_labels[:num_testing_samples]\n",
        "\n",
        "  # if(demographic_to_test != 'all'):\n",
        "    # testing_data_and_labels =  pd.DataFrame.reset_index(testing_data_and_labels.loc[testing_data_and_labels[demographic_to_test] > 0],drop=True)\n",
        "\n",
        "  #and training set to be the remainder\n",
        "  #this is also then consistent which is good for seeing patterns etc \n",
        "  training_data_and_labels = all_data_and_labels[num_testing_samples:]\n",
        "\n",
        "  # print(\"normalised\")\n",
        "  # print(training_data_and_labels)\n",
        "\n",
        "  # print(testing_data_and_labels)\n",
        "  return training_data_and_labels, testing_data_and_labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Vx5Lghqe2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training_data_and_labels, testing_data_and_labels = import_data(all_data, demographic_to_test)\n",
        "# training_data_and_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P5FvDlXt4se",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmKSjOeK4aRj",
        "colab_type": "text"
      },
      "source": [
        "##Selecting Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs36jQoqYmpp",
        "colab_type": "text"
      },
      "source": [
        "Here we select the classification model to use. We are using a selection of built-in classifiers in scikit-learn. \n",
        "\n",
        "Currently, we are using RBF SVM models (https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html). \n",
        "\n",
        "We define the boolean values ```vary_gamma ``` and  ```vary_c``` to define whether we are varying the gamma or C value in the classifiers. \n",
        "\n",
        "The model parameters are chosen in order to optimise for the overall loss, then optimised for the fairness criteria \"equalised odds\" for each demographic. This results in different models optimised for each demographic. We also have an overall \"most fair\" model, which trades off the discrimination measure for each demographic to find the 'optimal' parameters. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZv_kuCWYo_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection, neighbors, svm, gaussian_process, tree, ensemble, neural_network, metrics\n",
        "\n",
        "def define_classifiers():\n",
        "\n",
        "  vary_gamma = True\n",
        "  vary_c = False \n",
        "  gammas = []\n",
        "  cs = []\n",
        "  classifiers = []\n",
        "\n",
        "  if vary_gamma:\n",
        "    # gammas = [0.00001, 0.0005, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]\n",
        "    gammas = [0.00001]\n",
        "    cs = [100000]\n",
        "    # gammas = [0.001]\n",
        "    # gammas = [1]\n",
        "    # c_val = 1000\n",
        "    #fix size of C if varying gamma\n",
        "\n",
        "    for gamma_val in gammas:\n",
        "      for c_val in cs:\n",
        "        classifiers.append(svm.SVC(gamma=gamma_val,C=c_val, probability=True))\n",
        "\n",
        "  if vary_c:\n",
        "    cs = [10, 100, 1000, 10000, 100000, 1000000, 10000000, 10000000]\n",
        "    gamma_val = 1\n",
        "    #fix size of gamma if varying C\n",
        "    for c_val in cs:\n",
        "      classifiers.append(svm.SVC(gamma=gamma_val,C=c_val, probability=True))\n",
        "\n",
        "  return classifiers, gammas, cs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQD8oVE-a4-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define_classifiers()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7PUBJeb4SQh",
        "colab_type": "text"
      },
      "source": [
        "## Bootstrapping "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxB1XKpC4fYi",
        "colab_type": "text"
      },
      "source": [
        "The classification process then uses a bootstrapping procedure with the chosen model, to generate predictions of recidivism classifications (1 = will not reoffend (positive case); 0 = will reoffend (negative case)).\n",
        "\n",
        "Bootstrapping (https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_41) is a sampling with replacement procedure. The sample size is the same as the size of the (training) dataset. The bootstrapping procedure is run many times to generate different training datasets, which will then be used for classification. In turn, the classification results will be used to calculate and study the bias and variance errors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzZ6oTWgv3FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_bootstrap(training_data_and_labels):\n",
        "  # this is one bootstrap sample \n",
        "  indices = np.random.randint(0,training_data_and_labels.shape[0] , training_data_and_labels.shape[0])\n",
        "  indices.sort()\n",
        "  data_points = []\n",
        "\n",
        "  for i in indices:\n",
        "    data_points.append(training_data_and_labels.iloc[i])\n",
        "\n",
        "  b_sample = pd.DataFrame(data_points)\n",
        "  \n",
        "  return b_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RPB3I-bwLF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b_sample = do_bootstrap(training_data_and_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yArDHhIdCfIS",
        "colab_type": "text"
      },
      "source": [
        "### Calculate average prediction for each individual over all bootstrap samples "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjQeJu-rCpkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_avg_prediction(predictions):\n",
        "  #each row is bootstrap sample, each column an individual\n",
        "  return majority_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0p40u-y5sf2",
        "colab_type": "text"
      },
      "source": [
        "## Perform classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDUs2m5A6yP3",
        "colab_type": "text"
      },
      "source": [
        "Fit the model on the training data (which is one bootstrap data sample as defined above)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaofDUc-P8Mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(clf, b_sample, testing_data_and_labels):\n",
        "\n",
        "    #training data is everything apart from two year recid 0/1 label from the bootstrap sample\n",
        "    X_train = b_sample.drop(columns=['two_year_recid'])\n",
        "    y_train = b_sample['two_year_recid']\n",
        "    X_test = testing_data_and_labels.drop(columns=['two_year_recid'])\n",
        "    y_test = testing_data_and_labels['two_year_recid']\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    soft_score = clf.decision_function(X_test)\n",
        "    y_true = y_test\n",
        "\n",
        "    return y_pred, y_true, soft_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d8e8STm77eG",
        "colab_type": "text"
      },
      "source": [
        "Perform classification for each bootstrap sample separately, and store these in a DataFrame, to be passed into the bias/variance calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm8R-Gt-OmNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(training_data_and_labels, testing_data_and_labels, clf):\n",
        "    count = 0\n",
        "\n",
        "    num_bootstraps = len(training_data_and_labels);\n",
        "    while count <= num_bootstraps:\n",
        "      b_sample = do_bootstrap(training_data_and_labels)\n",
        "      y_pred, y_true, soft_score = fit_model(clf, b_sample, testing_data_and_labels)\n",
        "      if(count == 0):\n",
        "        predictions = pd.DataFrame(pd.Series(y_pred)).transpose()\n",
        "        #true labels are the same for every sample so we only need 1 row in df\n",
        "        true_labels = pd.DataFrame(pd.Series(y_true)).transpose()\n",
        "      else:\n",
        "        predictions = predictions.append(pd.DataFrame(pd.Series(y_pred)).transpose())\n",
        "      count += 1\n",
        "      \n",
        "    return predictions, true_labels, soft_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H75T2WV0OqIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classify(training_data_and_labels, testing_data_and_labels, clf)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TMfhfngzvTX",
        "colab_type": "text"
      },
      "source": [
        "## Correcting for Fairness\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBQkNPgD4D6o",
        "colab_type": "text"
      },
      "source": [
        "#Fairness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frcBqdbB3M22",
        "colab_type": "text"
      },
      "source": [
        "The definition of fairness is disputed, and there is not a single correct approach to ensuring fairness in machine learning. In general, as stated in https://arxiv.org/pdf/1711.08513.pdf, fairness in machine learning can be approached in two ways: fairness of the dataset itself; fairness of the model.\n",
        "\n",
        "Since we cannot control the process by which the data is collected, and the recidivism dataset already exists (likely with human and societal biases built-in), we will not be focusing on the former category. Although, there have been recent trends within the fairness and machine learning communities to argue the importance of the fairness in data collection, for example, in http://papers.nips.cc/paper/7613-why-is-my-classifier-discriminatory.pdf, the authors discuss the necessity of correcting for bias in the dataset, an approach which may actually increase the accuracy of the predictions, in contrast to approaches that exclusively focus on correcting for fairness in the models, at the expense of accuracy. Another area in which recent trends in fairness research have addressed is the importance of developing context-aware fairness measurements (https://arxiv.org/pdf/1805.05859.pdf). However, in our project we will focus on model-based fairness correction - ensuring the machine learning models are not perpetuating existing biases, or introducing new biases. We do this by using a widely used and accepted fairness measurement which is context-independent, known as **Equalised Odds** (http://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning.pdf). This approach is not without criticism, however it provides a clear and well-motivated approach to achieving fair predictions across subgroups with different protected characteristics. We attempt to correct for fairness in relation to the protected characteristics found in the recidivism dataset (sex, race, age). Once our models are 'fair' in relation to this description, we can explore the relationship between bias and variance errors and the potential discovery of discrimination against new categories. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vab-_uQEx46Q",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Equalised Odds\n",
        "\n",
        "As stated above, we are considering fairness in relation to the equalised odds metric (http://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning.pdf). The definition as stated in this paper is as follows: \\\\\n",
        "We say that a predictor $\\hat{Y}$ satisfies equalized odds with respect to\n",
        "protected attribute $A$ and outcome $Y$, if $\\hat{Y}$ and $A$ are independent conditional on $Y$. Therefore, if the classification labels are $Y$ and $\\hat{Y}$, for an outcome $ y=1 $, $\\hat{Y}$ has equal true positive rates across all demographic groups, for example, the categories not female and female will have equal true positive rates. For an outcome  $ y=0 $, $\\hat{Y}$ has equal false positive rates across all demographic groups. This enforces equal bias and accuracy in all demographics. This can formally be stated as:\n",
        "$$ Pr \\left\\{ \\hat{Y}=1 | A = 0, Y = y \\right\\} = Pr \\left\\{ \\hat{Y}=1 | A = 0, Y = y \\right\\} , y \\in \\left\\{ 0,1 \\right\\}$$\n",
        "\n",
        "This approach punishes models that only perform well on the majority demographics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cat-Jl0kJu2C",
        "colab_type": "text"
      },
      "source": [
        "The following code is the implementation of equalised odds from tha paper http://papers.nips.cc/paper/7151-on-fairness-and-calibration.pdf, the code is from the github repository https://github.com/gpleiss/equalized_odds_and_calibration/blob/master/eq_odds.py.\n",
        "\n",
        "This implementation equalises false positives and false negatives across demoographics, since in general, African Americans receive\n",
        "a disproportionate number of F.P. predictions as compared with Caucasians when automated risk tools are used in practice. In the context of recidivism, the 'positive case' is in fact a prediction of 0: the individual is predicted not to reoffend, so equalising false positives in this case fits with the equalised odds definition above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDXXgyFKJZOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_scores(predictions, soft_scores):\n",
        "\n",
        "  maximum = soft_scores.max()\n",
        "  minimum = soft_scores.min()\n",
        "\n",
        "  normalise = lambda x: ((x-minimum)/(maximum-minimum))\n",
        "  n_soft_scores = []\n",
        "  for score in soft_scores:\n",
        "    soft_score = normalise(score)\n",
        "    n_soft_scores.append(soft_score)\n",
        "\n",
        "  return n_soft_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPOMSx6442c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2WbfvPkLImE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def constrain_with_equalised_odds(predictions, true_labels, group_ids, demographic, soft_scores):\n",
        "\n",
        "  #create csv file containing relevant fields: prediction, label, group \n",
        "  predictions = pd.DataFrame(soft_scores, columns=['prediction'])\n",
        "  true_labels = pd.melt(true_labels).rename(columns={'value':'label'})\n",
        "  group_ids = pd.melt(group_ids).rename(columns={'value':'group'})\n",
        "  eq_odds_input = pd.concat([predictions, true_labels], axis=1)\n",
        "  eq_odds_input = pd.concat([eq_odds_input, group_ids], axis=1)\n",
        "  eq_odds_input = eq_odds_input.drop(columns=[\"variable\"])\n",
        "  eq_odds_input.to_csv('/content/drive/My Drive/project_data/eq_odds.csv', index=True)\n",
        "\n",
        "  !python2 \"/content/drive/My Drive/project_data/eq_odds.py\" \"/content/drive/My Drive/project_data/eq_odds.csv\"\n",
        "\n",
        "  eq_odds_pred_group_0 = pd.read_csv(filepath_or_buffer=\"/content/eq_odds_pred_group_0.csv\", delimiter=\",\")\n",
        "  eq_odds_pred_group_1 = pd.read_csv(filepath_or_buffer=\"/content/eq_odds_pred_group_1.csv\", delimiter=\",\")\n",
        "\n",
        "  print(eq_odds_pred_group_0)\n",
        "  #read in the output from the above file to get the new prediction values\n",
        "  #convert the predictions to the new labels\n",
        "  #then return these and do bias/var calculation etc on this \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5hobrODGwef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#this method doesn't actually make anything fair, it just calculates what we need in order to configure the models to be fair \n",
        "def calc_fairness_metrics(y_true, y_pred):\n",
        "  # get confusion matrix and compute tn,fp,fn,tp\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true.iloc[0].to_numpy(), y_pred.iloc[0].to_numpy()).ravel()\n",
        "  print(\"true negatives:\", tn, \"rate:\" , tn/(tn+fp+fn+tp), \"false positives:\", fp, \"rate:\", fp/(tn+fp+fn+tp) ,\"false negatives:\", fn,\"rate:\", fn/(tn+fp+fn+tp), \"true positives:\",tp,\"rate:\", tp/(tn+fp+fn+tp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnKB0sC3uU6-",
        "colab_type": "text"
      },
      "source": [
        "# Compute bias/variance errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdwnNxEnWqth",
        "colab_type": "text"
      },
      "source": [
        "Using all these bootstrap predictions, we calculate the average misclassification error which is the same as the zero-one loss. This is done by first calculating the overall misclassification loss across bootstrap sample predictions, finding the average misclassification error for each datapoint (individual). As described in:\n",
        "http://www.cems.uwe.ac.uk/~irjohnso/coursenotes/uqc832/tr-bias.pdf\n",
        "\n",
        "We can then decompose the error into the errors due to bias, and the errors due to variance, in order to study the behaviour of the model and the bias/variance tradeoff. This decomposition for classification is described in: \n",
        "https://homes.cs.washington.edu/~pedrod/bvd.pdf\n",
        "https://pdfs.semanticscholar.org/9253/f3e13bca7e845e60394d85ddaec0d4cfc6d6.pdf  \n",
        "\n",
        "<!-- https://www.stat.berkeley.edu/users/breiman/arcall96.pdf.  -->\n",
        "\n",
        "<!-- The error is also comprised of an error due to noise (in addition to bias and variance). However, as stated in http://papers.nips.cc/paper/7613-why-is-my-classifier-discriminatory.pdf, the noise is dependent on the data, not the model, so comparing the discrimination level in the form of bias and variance errors, the noise terms cancel since they are independent of the model. Therefore, differences in bias can be explored even without knowing the underlying noise of the data.  -->\n",
        "\n",
        "We calculate the bias and variance errors for each individual, following zero-one loss rules under misclassification loss, as described by Domingos https://homes.cs.washington.edu/~pedrod/bvd.pdf, http://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/. We can then calculate the overall average bias error and variance error for the prediction. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-7WHEx8dq6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_bias_variance(predictions, true_labels):\n",
        "\n",
        "  # print(\"predictions: \")\n",
        "  # print(predictions)\n",
        "  # print(\"true labels: \")\n",
        "\n",
        "  biases = []\n",
        "  variances = []\n",
        "  avg_errors = []\n",
        "  misclassified_individuals = []\n",
        "  losses = []\n",
        "  noises = []\n",
        "\n",
        "  # calculate the bias and variance for each value of X,y\n",
        "  # for misclassification loss\n",
        "\n",
        "  #to get the main prediction for each datapoint \n",
        "  main_predictions = predictions.mode()\n",
        "  main_predictions = pd.melt(main_predictions).iloc[:,1]\n",
        "  \n",
        "  #find whether each element is misclassified for each bootstrap sample \n",
        "  predictions_misclassified_relative_to_true = predictions.apply(lambda x : x != true_labels.iloc[0], axis=1)\n",
        "  #find if the main (mode) prediction is the same as the actual prediction\n",
        "  predictions_misclassified_relative_to_main = predictions.apply(lambda x : x != main_predictions, axis = 1)\n",
        "\n",
        "  #count number of times misclassified for each datapoint across all bootstrap samples \n",
        "  misclassified_true_counts = predictions_misclassified_relative_to_true.apply(np.sum)\n",
        "  misclassified_main_counts = predictions_misclassified_relative_to_main.apply(np.sum)\n",
        "\n",
        "  #average misclassification error for each individual/datapoint \n",
        "  #same as probability of incorrect classification\n",
        "  avg_true_errors = misclassified_true_counts.apply(lambda y : np.divide(y,len(predictions)))\n",
        "  avg_main_errors = misclassified_main_counts.apply(lambda y : np.divide(y,len(predictions)))\n",
        "\n",
        "  for i in range(len(avg_true_errors)):\n",
        "    # if average error is less than 0.5 then it means the main prediction is the same as the optimal one\n",
        "    avg_true_error = avg_true_errors[i]\n",
        "    avg_main_error = avg_main_errors[i]\n",
        "    bias = 0 if avg_true_error <=0.5 else 1\n",
        "    variance = avg_main_error\n",
        "    noise = 0\n",
        "    c1 = ((2*(1-avg_true_error))-1)\n",
        "    c2 = 1 if avg_main_error <= 0.5 else -1\n",
        "    #loss according to domingos' decomposition\n",
        "    loss = (c1*noise) + bias + (c2*variance)\n",
        "    biases.append(bias)\n",
        "    variances.append(variance)\n",
        "    noises.append(noise)\n",
        "    losses.append(loss)\n",
        "    if avg_true_error > 0.5:\n",
        "      misclassified_individuals.append(i)\n",
        "\n",
        "\n",
        "  print(misclassified_individuals)\n",
        "\n",
        "  avg_bias = np.mean(biases)\n",
        "  # avg_var = abs(np.mean(avg_errors) - avg_bias)\n",
        "  avg_var = np.mean(variances)\n",
        "  # avg_error = np.mean(avg_errors)\n",
        "  avg_loss = np.mean(losses)\n",
        "  avg_noise = np.mean(noises)\n",
        "\n",
        "  print(\"average loss:\") \n",
        "  print(avg_loss)\n",
        "  print(\"average noise:\")\n",
        "  print(avg_noise)\n",
        "  print(\"average bias:\")\n",
        "  print(avg_bias)\n",
        "  print(\"average variance:\")\n",
        "  print(avg_var)\n",
        "\n",
        "  return avg_bias, avg_var, avg_loss, misclassified_individuals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvS_8PYmsWxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1ygDcLeBeNq",
        "colab_type": "text"
      },
      "source": [
        "## Identifying Categories of Discrimination "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAxWqE2JBiT9",
        "colab_type": "text"
      },
      "source": [
        "We hope to address the question: Are models that exhibit high bias errors likely to introduce new categories of discrimination? \n",
        "\n",
        "We can therefore look at the bias and variance errors for different models.\n",
        "\n",
        "\n",
        "We want to see that if the variance is low and bias high, is it consistently discriminating against a certain subgroup, potentially introducing a new type of discrimination? Unlike other work such as http://papers.nips.cc/paper/7613-why-is-my-classifier-discriminatory.pdf, it doesn't have to be a protected characteristic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS-RcQVHudhq",
        "colab_type": "text"
      },
      "source": [
        "# Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kav2TxMqeTy2",
        "colab_type": "text"
      },
      "source": [
        "Creating the appropriate plots to visualise our results. We plot: \n",
        "\n",
        "1.   Bias error vs Variance error\n",
        "2.   Gamma value of RBF SVM vs Variance error\n",
        "3.   Gamma value of RBF SVM vs Bias error\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TcztpNvvfDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt                                  \n",
        "def plot_bias_variance(biases, variances, gammas, cs, losses):   \n",
        "  print(\"plotting bias/var\") \n",
        "  plt.scatter(biases, variances)                                              \n",
        "  plt.title('bias vs variance errors')                                     \n",
        "  plt.xlabel('bias')                                                       \n",
        "  plt.ylabel('variance')                                                   \n",
        "  plt.show()\n",
        "\n",
        "  plt.scatter(gammas, variances)\n",
        "  plt.xscale('log')                                              \n",
        "  plt.title('RBF SVM, C = 100000 \\n gamma size vs variance errors')                                     \n",
        "  plt.xlabel('gamma')                                                       \n",
        "  plt.ylabel('variance')                                                   \n",
        "  plt.show()                                                            \n",
        "\n",
        "  plt.scatter(gammas, biases)                               \n",
        "  plt.xscale('log')                                                             \n",
        "  plt.title('RBF SVM, C = 100000 \\n gamma size vs bias errors')                                     \n",
        "  plt.xlabel('gamma')                                                       \n",
        "  plt.ylabel('bias')                                                   \n",
        "  plt.show()            \n",
        "\n",
        "  plt.scatter(gammas, losses)                               \n",
        "  plt.xscale('log')                                                             \n",
        "  plt.title('RBF SVM, C = 100000 \\n gamma size vs total error')                                     \n",
        "  plt.xlabel('gamma')                                                       \n",
        "  plt.ylabel('error')                                                   \n",
        "  plt.show()   \n",
        "\n",
        "  # plt.scatter(cs, biases)                               \n",
        "  # plt.xscale('log')                                                             \n",
        "  # plt.title('RBF SVM, gamma=0.001, C value vs bias errors')                                     \n",
        "  # plt.xlabel('C value')                                                       \n",
        "  # plt.ylabel('bias')                                                   \n",
        "  # plt.show()       \n",
        "\n",
        "  # plt.scatter(cs, variances)                               \n",
        "  # plt.xscale('log')                                                             \n",
        "  # plt.title('RBF SVM, gamma=0.001, C value vs variance errors')                                     \n",
        "  # plt.xlabel('C value')                                                       \n",
        "  # plt.ylabel('variance')                                                   \n",
        "  # plt.show()       \n",
        "\n",
        "#just an example of if we want to plot the misclassified individuals against a characteristic from the dataframe \n",
        "#might help to look for patterns \n",
        "def plot_misclassified(misclassified):\n",
        "  misclassified.reset_index().plot(kind='scatter', x='index', y='age') \n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmVUHkRN8YMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download CSV file containing all the info for the individuals who are consistently misclassified (i.e. >50% of the time, resulting in bias errors)\n",
        "def download_misclassified(misclassified):\n",
        "  misclassified.reset_index().to_csv('misclassified.csv', index=False)\n",
        "  from google.colab import files\n",
        "  files.download('misclassified.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwemXVIVuhGq",
        "colab_type": "text"
      },
      "source": [
        "# Main method (execute code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vpU8QERWV4i",
        "colab_type": "text"
      },
      "source": [
        "Main method to run the system, executing methods in appropriate sequence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCBsC158supR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  all_data = load_file()\n",
        "  # demographics = ['african-american', 'caucasian', 'hispanic', 'asian', 'other', 'male', 'female', 'less than 25', '25 - 45', 'greater than 45']\n",
        "  demographics = ['african-american']\n",
        "  # demographics = [ 'hispanic', 'asian', 'other', 'male', 'female', 'less than 25', '25 - 45', 'greater than 45']\n",
        "  testing_data_and_labels_list = []\n",
        "  training_data_and_labels_list = []\n",
        "  training_data_and_labels, testing_data_and_labels = import_data(all_data)\n",
        "  training_data_and_labels_list.append(training_data_and_labels)\n",
        "  testing_data_and_labels_list.append(testing_data_and_labels)\n",
        "\n",
        "  biases = []\n",
        "  variances = []\n",
        "  total_errors = []\n",
        "  avg_losses = []\n",
        "  classifiers, gammas, cs = define_classifiers()\n",
        "  misclassified = []\n",
        "  equalised_odds = True\n",
        "\n",
        "  for classifier in classifiers:\n",
        "    print(classifier)\n",
        "    # clf = classifiers[classifier_names.index(classifier)]\n",
        "    clf = classifier\n",
        "    for i in range(len(training_data_and_labels_list)):\n",
        "      # print('testing ', demographics[i], '=', true_case)\n",
        "      predictions, true_labels, soft_scores = classify(training_data_and_labels_list[i], testing_data_and_labels_list[i], clf)  \n",
        "      soft_scores = calculate_scores(predictions, soft_scores)\n",
        "      majority_predictions = predictions.mode(numeric_only=True)\n",
        "      if(equalised_odds):\n",
        "        # calc_fairness_metrics(true_labels, majority_predictions)\n",
        "        for demographic in demographics:\n",
        "          group_ids = [] \n",
        "          print(\"Equalising odds for \", demographic)\n",
        "          group_ids_normalised = testing_data_and_labels[demographic]\n",
        "          for n_id in group_ids_normalised:\n",
        "            group_id = 0 if n_id < 0 else 1\n",
        "            group_ids.append(group_id)\n",
        "          group_ids = pd.DataFrame([group_ids])\n",
        "          eq_odds_labels = constrain_with_equalised_odds(majority_predictions, true_labels, group_ids, demographic, soft_scores)\n",
        "      bias, variance, avg_loss, misclassified_individuals = compute_bias_variance(predictions, true_labels)\n",
        "      biases.append(bias)\n",
        "      variances.append(variance)\n",
        "      avg_losses.append(avg_loss)\n",
        "      #get the individuals which are misclassified on average (hence contributing to bias errors)\n",
        "      print(misclassified_individuals)\n",
        "      if(len(misclassified) > 0 ):\n",
        "        misclassified = testing_data_and_labels_list[i].iloc[misclassified_individuals]\n",
        "      # download_misclassified(misclassified)\n",
        "      # plot_misclassified(misclassified)\n",
        "\n",
        "  # plot_bias_variance(biases, variances, gammas, cs, avg_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA8uQhlb8ARv",
        "colab_type": "code",
        "outputId": "926e6344-73ee-4ad5-df6b-a425d4ae90b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 619,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data\n",
            "loaded data\n",
            "SVC(C=100000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=1e-05, kernel='rbf',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "Equalising odds for  african-american\n",
            "/content/drive/My Drive/project_data/eq_odds.py:214: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  group_0_val_model = Model(group_0_val_data['prediction'].as_matrix(), group_0_val_data['label'].as_matrix())\n",
            "/content/drive/My Drive/project_data/eq_odds.py:215: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  group_1_val_model = Model(group_1_val_data['prediction'].as_matrix(), group_1_val_data['label'].as_matrix())\n",
            "/content/drive/My Drive/project_data/eq_odds.py:216: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  group_0_test_model = Model(group_0_test_data['prediction'].as_matrix(), group_0_test_data['label'].as_matrix())\n",
            "/content/drive/My Drive/project_data/eq_odds.py:217: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  group_1_test_model = Model(group_1_test_data['prediction'].as_matrix(), group_1_test_data['label'].as_matrix())\n",
            "Original group 0 model:\n",
            "Accuracy:\t0.929\n",
            "F.P. cost:\t0.149\n",
            "F.N. cost:\t0.338\n",
            "Base rate:\t0.500\n",
            "Avg. score:\t0.406\n",
            "\n",
            "Predictions: \n",
            "[0.15429873 0.13609795 0.84915044 0.14228901 0.94820011 0.64638449\n",
            " 1.         0.63108629 0.24921989 0.70088913 0.52344011 0.05939093\n",
            " 0.67692441 0.13411649 0.14176129 0.34946078 0.65580743 0.39383833\n",
            " 0.08105777 0.584928   0.12812453 0.11978577 0.65885921 0.07241744\n",
            " 0.58897958 0.64312352 0.14713495 0.6003709  0.13808377 0.15429873\n",
            " 0.77731002 0.1470069  0.37150552 0.69759114 0.12830861 0.14993612\n",
            " 0.13130925 0.13872088 0.11998189 0.16399127 0.67701543 0.58517939\n",
            " 0.87223686 0.85251061 0.87340863 0.50010863 0.12834246 0.51014547\n",
            " 0.54110906 0.07055873 0.06756771 0.38837574 0.66175476 0.1541562\n",
            " 0.6388485  0.06091112]\n",
            "True labels: \n",
            "[0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0]\n",
            "Original group 1 model:\n",
            "Accuracy:\t0.818\n",
            "F.P. cost:\t0.250\n",
            "F.N. cost:\t0.346\n",
            "Base rate:\t0.682\n",
            "Avg. score:\t0.526\n",
            "\n",
            "Predictions: \n",
            "[0.60445119 0.63773204 0.05246607 0.120185   0.12009414 0.61779361\n",
            " 0.54756825 0.6843564  0.74862484 0.06078845 0.69065941 0.84979405\n",
            " 0.77104257 0.63567411 0.49382762 0.85491139 0.64982732 0.57699143\n",
            " 0.83838143 0.11458074 0.46850514 0.11994908 0.84495909 0.88921383\n",
            " 0.702188   0.56725502 0.62275614 0.63338761 0.42766185 0.45825761\n",
            " 0.12011519 0.46973432 0.13056757 0.10961264 0.94864    0.51524157\n",
            " 0.67395997 0.6355179  0.12149308 0.82759365 0.89749783 0.57573147\n",
            " 0.12143679 0.57772245]\n",
            "True labels: \n",
            "[1 1 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1\n",
            " 1 0 1 1 1 0 1]\n",
            "Equalized odds group 0 model:\n",
            "Accuracy:\t0.929\n",
            "F.P. cost:\t0.149\n",
            "F.N. cost:\t0.338\n",
            "Base rate:\t0.500\n",
            "Avg. score:\t0.406\n",
            "\n",
            "Predictions: \n",
            "[0.15429873 0.13609795 0.84915044 0.14228901 0.94820011 0.64638449\n",
            " 1.         0.63108629 0.24921989 0.70088913 0.52344011 0.05939093\n",
            " 0.67692441 0.13411649 0.14176129 0.34946078 0.65580743 0.39383833\n",
            " 0.08105777 0.584928   0.12812453 0.11978577 0.65885921 0.07241744\n",
            " 0.58897958 0.64312352 0.14713495 0.6003709  0.13808377 0.15429873\n",
            " 0.77731002 0.1470069  0.37150552 0.69759114 0.12830861 0.14993612\n",
            " 0.13130925 0.13872088 0.11998189 0.16399127 0.67701543 0.58517939\n",
            " 0.87223686 0.85251061 0.87340863 0.50010863 0.12834246 0.51014547\n",
            " 0.54110906 0.07055873 0.06756771 0.38837574 0.66175476 0.1541562\n",
            " 0.6388485  0.06091112]\n",
            "True labels: \n",
            "[0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0]\n",
            "Equalized odds group 1 model:\n",
            "Accuracy:\t0.818\n",
            "F.P. cost:\t0.151\n",
            "F.N. cost:\t0.371\n",
            "Base rate:\t0.682\n",
            "Avg. score:\t0.477\n",
            "\n",
            "Predictions: \n",
            "[0.60445119 0.63773204 0.05246607 0.120185   0.12009414 0.61779361\n",
            " 0.54756825 0.6843564  0.25137516 0.06078845 0.69065941 0.15020595\n",
            " 0.77104257 0.63567411 0.49382762 0.85491139 0.64982732 0.57699143\n",
            " 0.16161857 0.11458074 0.46850514 0.11994908 0.84495909 0.88921383\n",
            " 0.702188   0.56725502 0.62275614 0.63338761 0.42766185 0.45825761\n",
            " 0.12011519 0.46973432 0.13056757 0.10961264 0.94864    0.51524157\n",
            " 0.67395997 0.3644821  0.12149308 0.82759365 0.89749783 0.57573147\n",
            " 0.12143679 0.57772245]\n",
            "True labels: \n",
            "[1 1 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1\n",
            " 1 0 1 1 1 0 1]\n",
            "    1.542987325474171056e-01\n",
            "0                   0.136098\n",
            "1                   0.849150\n",
            "2                   0.142289\n",
            "3                   0.948200\n",
            "4                   0.646384\n",
            "5                   1.000000\n",
            "6                   0.631086\n",
            "7                   0.249220\n",
            "8                   0.700889\n",
            "9                   0.523440\n",
            "10                  0.059391\n",
            "11                  0.676924\n",
            "12                  0.134116\n",
            "13                  0.141761\n",
            "14                  0.349461\n",
            "15                  0.655807\n",
            "16                  0.393838\n",
            "17                  0.081058\n",
            "18                  0.584928\n",
            "19                  0.128125\n",
            "20                  0.119786\n",
            "21                  0.658859\n",
            "22                  0.072417\n",
            "23                  0.588980\n",
            "24                  0.643124\n",
            "25                  0.147135\n",
            "26                  0.600371\n",
            "27                  0.138084\n",
            "28                  0.154299\n",
            "29                  0.777310\n",
            "30                  0.147007\n",
            "31                  0.371506\n",
            "32                  0.697591\n",
            "33                  0.128309\n",
            "34                  0.149936\n",
            "35                  0.131309\n",
            "36                  0.138721\n",
            "37                  0.119982\n",
            "38                  0.163991\n",
            "39                  0.677015\n",
            "40                  0.585179\n",
            "41                  0.872237\n",
            "42                  0.852511\n",
            "43                  0.873409\n",
            "44                  0.500109\n",
            "45                  0.128342\n",
            "46                  0.510145\n",
            "47                  0.541109\n",
            "48                  0.070559\n",
            "49                  0.067568\n",
            "50                  0.388376\n",
            "51                  0.661755\n",
            "52                  0.154156\n",
            "53                  0.638848\n",
            "54                  0.060911\n",
            "[29, 30, 34, 45, 48, 54, 65, 74, 132, 134, 135, 137, 139, 146, 149, 168, 175, 188, 189, 192, 199]\n",
            "average loss:\n",
            "0.20187384246649964\n",
            "average noise:\n",
            "0.0\n",
            "average bias:\n",
            "0.1044776119402985\n",
            "average variance:\n",
            "0.09739623052620111\n",
            "[29, 30, 34, 45, 48, 54, 65, 74, 132, 134, 135, 137, 139, 146, 149, 168, 175, 188, 189, 192, 199]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3DmkHHZKh3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}